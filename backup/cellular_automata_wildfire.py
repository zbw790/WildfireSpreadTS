#!/usr/bin/env python3
"""
Cellular Automata (CA) é‡ç«ä¼ æ’­æ¨¡å‹
åŸºäºç‰©ç†è§„åˆ™çš„å…ƒèƒè‡ªåŠ¨æœºæ¨¡æ‹Ÿé‡ç«ä¼ æ’­åŠ¨åŠ›å­¦
"""

import numpy as np
import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import Dataset, DataLoader
import matplotlib.pyplot as plt
import matplotlib.animation as animation
from matplotlib.colors import ListedColormap
import seaborn as sns
from pathlib import Path
import json
import time
import h5py
from sklearn.metrics import average_precision_score, precision_recall_curve
import warnings
warnings.filterwarnings('ignore')

class FireState:
    """ç«ç¾çŠ¶æ€æšä¸¾"""
    UNBURNED = 0      # æœªç‡ƒçƒ§
    BURNING = 1       # æ­£åœ¨ç‡ƒçƒ§
    BURNED = 2        # å·²ç‡ƒçƒ§å®Œæ¯•
    WATER = 3         # æ°´ä½“/ä¸å¯ç‡ƒ
    
class CellularAutomataCore:
    """å…ƒèƒè‡ªåŠ¨æœºæ ¸å¿ƒå¼•æ“"""
    
    def __init__(self, grid_size=(128, 128)):
        self.grid_size = grid_size
        self.H, self.W = grid_size
        
        # é‚»åŸŸå®šä¹‰ï¼ˆ8é‚»åŸŸ + æ‰©å±•é‚»åŸŸï¼‰
        self.neighbors_8 = [
            (-1, -1), (-1, 0), (-1, 1),
            ( 0, -1),          ( 0, 1),
            ( 1, -1), ( 1, 0), ( 1, 1)
        ]
        
        # é£å‘å½±å“æƒé‡ï¼ˆ8ä¸ªæ–¹å‘ï¼‰
        self.wind_directions = {
            'N':  (-1, 0),  'NE': (-1, 1),  'E':  (0, 1),  'SE': (1, 1),
            'S':  (1, 0),   'SW': (1, -1),  'W':  (0, -1), 'NW': (-1, -1)
        }
        
        print(f"ğŸ”¥ CAå¼•æ“åˆå§‹åŒ–å®Œæˆï¼Œç½‘æ ¼å¤§å°: {grid_size}")
    
    def get_wind_direction_name(self, wind_angle):
        """å°†é£å‘è§’åº¦è½¬æ¢ä¸ºæ–¹å‘åç§°"""
        # æ ‡å‡†åŒ–è§’åº¦åˆ° 0-360
        wind_angle = wind_angle % 360
        
        # å°†è§’åº¦è½¬æ¢ä¸º8ä¸ªåŸºæœ¬æ–¹å‘
        directions = ['N', 'NE', 'E', 'SE', 'S', 'SW', 'W', 'NW']
        idx = int((wind_angle + 22.5) // 45) % 8
        return directions[idx]
    
    def calculate_fire_probability(self, i, j, fire_state, fuel_load, moisture, 
                                 wind_speed, wind_direction, temperature, slope):
        """è®¡ç®—å•ä¸ªæ ¼å­çš„ç€ç«æ¦‚ç‡"""
        
        # åŸºç¡€æ¦‚ç‡
        base_prob = 0.01
        
        # å¦‚æœå·²ç»æ˜¯æ°´ä½“ï¼Œæ¦‚ç‡ä¸º0
        if fire_state[i, j] == FireState.WATER:
            return 0.0
        
        # å¦‚æœå·²ç»ç‡ƒçƒ§è¿‡ï¼Œæ¦‚ç‡ä¸º0
        if fire_state[i, j] == FireState.BURNED:
            return 0.0
        
        # ç‡ƒæ–™è´Ÿè·å½±å“ (0-1æ ‡å‡†åŒ–)
        fuel_factor = np.clip(fuel_load[i, j] / 100.0, 0, 1)
        
        # æ¹¿åº¦å½±å“ (æ¹¿åº¦è¶Šé«˜ï¼Œç€ç«æ¦‚ç‡è¶Šä½)
        moisture_factor = np.clip(1 - moisture[i, j] / 100.0, 0.1, 1)
        
        # æ¸©åº¦å½±å“ (æ¸©åº¦è¶Šé«˜ï¼Œç€ç«æ¦‚ç‡è¶Šé«˜)
        temp_factor = np.clip((temperature[i, j] + 20) / 60.0, 0.1, 2)
        
        # å¡åº¦å½±å“ (å¡åº¦è¶Šå¤§ï¼Œç«åŠ¿ä¼ æ’­è¶Šå¿«)
        slope_factor = 1 + np.clip(slope[i, j] / 45.0, 0, 1) * 0.5
        
        # é‚»åŸŸç«æºå½±å“
        neighbor_fire_factor = self._calculate_neighbor_influence(
            i, j, fire_state, wind_speed, wind_direction
        )
        
        # ç»¼åˆæ¦‚ç‡è®¡ç®—
        total_prob = (base_prob * 
                     fuel_factor * 
                     moisture_factor * 
                     temp_factor * 
                     slope_factor * 
                     neighbor_fire_factor)
        
        return np.clip(total_prob, 0, 1)
    
    def _calculate_neighbor_influence(self, i, j, fire_state, wind_speed, wind_direction):
        """è®¡ç®—é‚»åŸŸç«æºå½±å“"""
        influence = 1.0
        
        # è·å–é£å‘
        wind_dir_name = self.get_wind_direction_name(wind_direction)
        wind_vector = self.wind_directions[wind_dir_name]
        wind_strength = np.clip(wind_speed / 20.0, 0, 3)  # é£é€Ÿå½±å“å› å­
        
        for di, dj in self.neighbors_8:
            ni, nj = i + di, j + dj
            
            # è¾¹ç•Œæ£€æŸ¥
            if 0 <= ni < self.H and 0 <= nj < self.W:
                if fire_state[ni, nj] == FireState.BURNING:
                    # åŸºç¡€é‚»åŸŸå½±å“
                    base_influence = 2.0
                    
                    # é£å‘å½±å“ï¼šé¡ºé£æ–¹å‘å½±å“æ›´å¤§
                    wind_factor = 1.0
                    if wind_strength > 0.1:
                        # è®¡ç®—ä»é‚»å±…åˆ°å½“å‰ä½ç½®çš„æ–¹å‘å‘é‡
                        direction_vector = (-di, -dj)  # æ³¨æ„æ–¹å‘
                        
                        # è®¡ç®—ä¸é£å‘çš„å¤¹è§’å½±å“
                        dot_product = (direction_vector[0] * wind_vector[0] + 
                                     direction_vector[1] * wind_vector[1])
                        
                        # é¡ºé£æ—¶å½±å“å¢å¼ºï¼Œé€†é£æ—¶å½±å“å‡å¼±
                        wind_factor = 1 + wind_strength * dot_product * 0.5
                        wind_factor = max(0.5, wind_factor)  # æœ€å°ä¿æŒ50%å½±å“
                    
                    # è·ç¦»å½±å“ï¼ˆé‚»åŸŸè·ç¦»ï¼‰
                    distance = np.sqrt(di*di + dj*dj)
                    distance_factor = 1.0 / distance if distance > 0 else 1.0
                    
                    influence += base_influence * wind_factor * distance_factor
        
        return influence
    
    def step_evolution(self, fire_state, fuel_load, moisture, wind_speed, 
                      wind_direction, temperature, slope, ignition_prob=None):
        """æ‰§è¡Œä¸€æ­¥æ¼”åŒ–"""
        new_fire_state = fire_state.copy()
        
        # éå†æ‰€æœ‰æ ¼å­
        for i in range(self.H):
            for j in range(self.W):
                current_state = fire_state[i, j]
                
                if current_state == FireState.UNBURNED:
                    # è®¡ç®—ç€ç«æ¦‚ç‡
                    fire_prob = self.calculate_fire_probability(
                        i, j, fire_state, fuel_load, moisture,
                        wind_speed[i, j], wind_direction[i, j], 
                        temperature[i, j], slope[i, j]
                    )
                    
                    # å¤–éƒ¨ç‚¹ç«æ¦‚ç‡
                    if ignition_prob is not None:
                        fire_prob = max(fire_prob, ignition_prob[i, j])
                    
                    # éšæœºç‚¹ç«
                    if np.random.random() < fire_prob:
                        new_fire_state[i, j] = FireState.BURNING
                
                elif current_state == FireState.BURNING:
                    # ç‡ƒçƒ§ä¸€æ®µæ—¶é—´åå˜ä¸ºå·²ç‡ƒçƒ§
                    # ç®€åŒ–æ¨¡å‹ï¼šç‡ƒçƒ§ä¸€æ­¥åå°±å˜ä¸ºå·²ç‡ƒçƒ§
                    burnout_prob = 0.3 + 0.4 * (1 - fuel_load[i, j] / 100.0)
                    if np.random.random() < burnout_prob:
                        new_fire_state[i, j] = FireState.BURNED
        
        return new_fire_state

class LearnableCA(nn.Module):
    """å¯å­¦ä¹ çš„å…ƒèƒè‡ªåŠ¨æœº"""
    
    def __init__(self, input_channels=22, hidden_dim=64, grid_size=(128, 128)):
        super(LearnableCA, self).__init__()
        
        self.input_channels = input_channels
        self.hidden_dim = hidden_dim
        self.grid_size = grid_size
        
        # ç¯å¢ƒç‰¹å¾ç¼–ç å™¨
        self.env_encoder = nn.Sequential(
            nn.Conv2d(input_channels, hidden_dim, 3, padding=1),
            nn.BatchNorm2d(hidden_dim),
            nn.ReLU(inplace=True),
            nn.Conv2d(hidden_dim, hidden_dim, 3, padding=1),
            nn.BatchNorm2d(hidden_dim),
            nn.ReLU(inplace=True)
        )
        
        # CAè§„åˆ™ç½‘ç»œ
        self.ca_rule = nn.Sequential(
            nn.Conv2d(hidden_dim + 4, hidden_dim, 3, padding=1),  # +4 for fire states
            nn.BatchNorm2d(hidden_dim),
            nn.ReLU(inplace=True),
            nn.Conv2d(hidden_dim, hidden_dim//2, 3, padding=1),
            nn.BatchNorm2d(hidden_dim//2),
            nn.ReLU(inplace=True),
            nn.Conv2d(hidden_dim//2, 4, 1),  # 4ä¸ªçŠ¶æ€çš„æ¦‚ç‡
        )
        
        # é£å‘å½±å“ç½‘ç»œ
        self.wind_influence = self._create_wind_networks()
        
        # çŠ¶æ€è½¬ç§»æ¦‚ç‡ç½‘ç»œ
        self.transition_net = nn.Sequential(
            nn.Conv2d(hidden_dim, 32, 1),
            nn.ReLU(inplace=True),
            nn.Conv2d(32, 1, 1),
            nn.Sigmoid()
        )
        
    def _create_wind_networks(self):
        """åˆ›å»º8ä¸ªæ–¹å‘çš„é£å‘å½±å“ç½‘ç»œ"""
        wind_nets = nn.ModuleDict()
        
        # 8ä¸ªä¸»è¦é£å‘
        directions = ['N', 'NE', 'E', 'SE', 'S', 'SW', 'W', 'NW']
        
        for direction in directions:
            # åˆ›å»ºå¯å­¦ä¹ çš„å·ç§¯å±‚ï¼ˆè€Œä¸æ˜¯å›ºå®šæƒé‡ï¼‰
            conv = nn.Conv2d(1, 1, 3, padding=1, bias=False)
            # åˆå§‹åŒ–ä¸ºåˆç†çš„é£å‘æƒé‡
            with torch.no_grad():
                if direction in ['N', 'S']:
                    conv.weight.data = torch.tensor([[[
                        [0.1, 0.2, 0.1],
                        [0.2, 1.0, 0.2],
                        [0.1, 0.2, 0.1]
                    ]]], dtype=torch.float32)
                elif direction in ['E', 'W']:
                    conv.weight.data = torch.tensor([[[
                        [0.1, 0.2, 0.1],
                        [0.2, 1.0, 0.2],
                        [0.1, 0.2, 0.1]
                    ]]], dtype=torch.float32)
                else:  # å¯¹è§’æ–¹å‘
                    conv.weight.data = torch.tensor([[[
                        [0.1, 0.1, 0.1],
                        [0.1, 1.0, 0.3],
                        [0.1, 0.1, 0.1]
                    ]]], dtype=torch.float32)
            
            wind_nets[direction] = conv
        
        return wind_nets
    
    def apply_wind_influence(self, fire_state, wind_speed, wind_direction):
        """åº”ç”¨é£å‘å½±å“"""
        batch_size = fire_state.size(0)
        influenced_fire = torch.zeros_like(fire_state)
        
        # å°†é£å‘è½¬æ¢ä¸º8ä¸ªæ–¹å‘çš„æƒé‡
        directions = ['N', 'NE', 'E', 'SE', 'S', 'SW', 'W', 'NW']
        
        for b in range(batch_size):
            for direction in directions:
                # è®¡ç®—è¯¥æ–¹å‘çš„æƒé‡
                dir_angle = directions.index(direction) * 45
                wind_angle = wind_direction[b, 0].mean().item()  # ç®€åŒ–ï¼šä½¿ç”¨å¹³å‡é£å‘
                
                # è®¡ç®—æ–¹å‘åŒ¹é…åº¦
                angle_diff = abs(wind_angle - dir_angle)
                angle_diff = min(angle_diff, 360 - angle_diff)
                direction_weight = max(0, 1 - angle_diff / 90.0)  # 90åº¦å†…æœ‰æ•ˆ
                
                # é£é€Ÿå½±å“
                wind_strength = wind_speed[b, 0].mean().item() / 20.0  # æ ‡å‡†åŒ–åˆ°0-1
                wind_strength = np.clip(wind_strength, 0, 1)
                
                # åº”ç”¨é£å‘å·ç§¯
                if direction_weight > 0.1 and wind_strength > 0.1:
                    wind_effect = self.wind_influence[direction](fire_state[b:b+1, 0:1])
                    influenced_fire[b:b+1, 0:1] += (wind_effect * 
                                                   direction_weight * 
                                                   wind_strength)
        
        return influenced_fire
    
    def forward(self, env_features, initial_fire_state, num_steps=5):
        """å‰å‘ä¼ æ’­ï¼šæ‰§è¡ŒCAæ¼”åŒ–"""
        batch_size = env_features.size(0)
        
        # ç¼–ç ç¯å¢ƒç‰¹å¾
        env_encoded = self.env_encoder(env_features)
        
        # æå–å…³é”®ç¯å¢ƒå˜é‡
        wind_speed = env_features[:, 8:9]      # é£é€Ÿ
        wind_direction = env_features[:, 7:8]  # é£å‘
        
        # åˆå§‹åŒ–ç«ç¾çŠ¶æ€
        fire_state = initial_fire_state.clone()
        fire_evolution = [fire_state.clone()]
        
        # CAæ¼”åŒ–å¾ªç¯
        for step in range(num_steps):
            # å‡†å¤‡CAè¾“å…¥ï¼šç¯å¢ƒç‰¹å¾ + å½“å‰ç«ç¾çŠ¶æ€
            fire_state_encoded = self._encode_fire_state(fire_state)
            ca_input = torch.cat([env_encoded, fire_state_encoded], dim=1)
            
            # è®¡ç®—çŠ¶æ€è½¬ç§»æ¦‚ç‡
            transition_logits = self.ca_rule(ca_input)
            transition_probs = F.softmax(transition_logits, dim=1)
            
            # åº”ç”¨é£å‘å½±å“
            wind_influence = self.apply_wind_influence(fire_state, wind_speed, wind_direction)
            
            # æ›´æ–°ç«ç¾çŠ¶æ€
            fire_state = self._update_fire_state(
                fire_state, transition_probs, wind_influence
            )
            
            fire_evolution.append(fire_state.clone())
        
        return fire_state, fire_evolution
    
    def _encode_fire_state(self, fire_state):
        """å°†ç«ç¾çŠ¶æ€ç¼–ç ä¸ºone-hotå½¢å¼"""
        batch_size, _, H, W = fire_state.shape
        
        # å°†è¿ç»­å€¼è½¬æ¢ä¸ºç¦»æ•£çŠ¶æ€
        fire_discrete = torch.zeros_like(fire_state).long()
        fire_discrete[fire_state < 0.25] = FireState.UNBURNED
        fire_discrete[(fire_state >= 0.25) & (fire_state < 0.75)] = FireState.BURNING
        fire_discrete[fire_state >= 0.75] = FireState.BURNED
        
        # One-hotç¼–ç 
        fire_one_hot = F.one_hot(fire_discrete.squeeze(1), num_classes=4).permute(0, 3, 1, 2).float()
        
        return fire_one_hot
    
    def _update_fire_state(self, current_state, transition_probs, wind_influence):
        """æ›´æ–°ç«ç¾çŠ¶æ€ - ä½¿ç”¨å¯å¾®åˆ†çš„è½¯æ›´æ–°"""
        batch_size, _, H, W = current_state.shape
        
        # åº”ç”¨é£å‘å½±å“
        wind_boost = torch.sigmoid(wind_influence) * 0.3
        
        # ä½¿ç”¨è½¯æ›´æ–°è€Œä¸æ˜¯ç¡¬é˜ˆå€¼ï¼Œä¿æŒæ¢¯åº¦è¿ç»­æ€§
        # æå–å„çŠ¶æ€çš„æ¦‚ç‡
        prob_unburned = transition_probs[:, 0:1]
        prob_burning = transition_probs[:, 1:2] + wind_boost
        prob_burned = transition_probs[:, 2:3]
        
        # è½¯çŠ¶æ€è½¬ç§» - ä½¿ç”¨åŠ æƒå¹³å‡è€Œä¸æ˜¯ç¡¬åˆ†ç±»
        # å½“å‰çŠ¶æ€æƒé‡
        current_weight = 0.7
        
        # è®¡ç®—æ–°çŠ¶æ€å€¼
        # 0.0 = æœªç‡ƒçƒ§, 0.5 = ç‡ƒçƒ§, 1.0 = å·²ç‡ƒçƒ§
        target_state = (prob_unburned * 0.0 + 
                       prob_burning * 0.5 + 
                       prob_burned * 1.0)
        
        # è½¯æ›´æ–°ï¼šä¿ç•™éƒ¨åˆ†å½“å‰çŠ¶æ€ï¼Œæ··åˆç›®æ ‡çŠ¶æ€
        new_state = current_weight * current_state + (1 - current_weight) * target_state
        
        # ç¡®ä¿çŠ¶æ€åœ¨åˆç†èŒƒå›´å†…
        new_state = torch.clamp(new_state, 0.0, 1.0)
        
        return new_state

class CAWildfireDataset(Dataset):
    """CAæ¨¡å‹ä¸“ç”¨æ•°æ®é›†"""
    
    def __init__(self, data_dir, mode='train', max_files=100, target_size=(128, 128)):
        self.data_dir = Path(data_dir)
        self.mode = mode
        self.target_size = target_size
        
        print(f"ğŸ”¥ åˆå§‹åŒ–CAæ•°æ®é›† ({mode}æ¨¡å¼)")
        
        # æ”¶é›†æ–‡ä»¶
        self._collect_files(max_files)
        
        # æ„å»ºæ ·æœ¬
        self.samples = []
        self._build_samples()
        
        print(f"âœ… CAæ•°æ®é›†åˆå§‹åŒ–å®Œæˆ: {len(self)} ä¸ªæ ·æœ¬")
    
    def _collect_files(self, max_files):
        """æ”¶é›†HDF5æ–‡ä»¶"""
        all_files = []
        for year in ['2018', '2019', '2020', '2021']:
            year_dir = self.data_dir / year
            if year_dir.exists():
                year_files = list(year_dir.glob("*.hdf5"))
                all_files.extend(year_files)
        
        files_to_use = all_files[:max_files]
        n_files = len(files_to_use)
        
        if self.mode == 'train':
            self.files = files_to_use[:int(0.8 * n_files)]
        else:
            self.files = files_to_use[int(0.8 * n_files):]
        
        print(f"ğŸ“ {self.mode}æ¨¡å¼ä½¿ç”¨ {len(self.files)} ä¸ªæ–‡ä»¶")
    
    def _build_samples(self):
        """æ„å»ºæ—¶åºæ ·æœ¬"""
        for file_idx, file_path in enumerate(self.files):
            try:
                with h5py.File(file_path, 'r') as f:
                    n_timesteps = f['data'].shape[0]
                    
                    # åˆ›å»ºæ—¶åºåºåˆ—ï¼ˆCAéœ€è¦æ—¶åºæ¼”åŒ–ï¼‰
                    seq_length = 5  # CAæ¼”åŒ–æ­¥æ•°
                    for t in range(0, n_timesteps - seq_length + 1, 2):
                        self.samples.append((file_idx, t, seq_length))
                        
            except Exception as e:
                print(f"è·³è¿‡æ–‡ä»¶ {file_path}: {e}")
                continue
    
    def __len__(self):
        return len(self.samples)
    
    def __getitem__(self, idx):
        file_idx, start_t, seq_length = self.samples[idx]
        file_path = self.files[file_idx]
        
        try:
            with h5py.File(file_path, 'r') as f:
                # è¯»å–æ—¶åºæ•°æ®
                sequence_data = f['data'][start_t:start_t+seq_length]  # (T, C, H, W)
                
                # è½¬æ¢ä¸ºtensor
                sequence_tensor = torch.from_numpy(sequence_data).float()
                
                # Resize
                if sequence_tensor.shape[2:] != self.target_size:
                    T, C = sequence_tensor.shape[:2]
                    sequence_resized = F.interpolate(
                        sequence_tensor.view(T*C, 1, *sequence_tensor.shape[2:]),
                        size=self.target_size,
                        mode='bilinear',
                        align_corners=False
                    ).view(T, C, *self.target_size)
                else:
                    sequence_resized = sequence_tensor
                
                # åˆ†ç¦»ç¯å¢ƒç‰¹å¾å’Œç«ç¾çŠ¶æ€
                env_features = sequence_resized[0, :22]  # åˆå§‹ç¯å¢ƒç‰¹å¾
                initial_fire = sequence_resized[0, 22:23]  # åˆå§‹ç«ç¾çŠ¶æ€
                target_fire = sequence_resized[-1, 22:23]  # æœ€ç»ˆç«ç¾çŠ¶æ€
                
                # æ•°æ®æ¸…æ´—
                env_features = torch.where(torch.isfinite(env_features), 
                                         env_features, torch.tensor(0.0))
                initial_fire = torch.where(torch.isfinite(initial_fire), 
                                         initial_fire, torch.tensor(0.0))
                target_fire = torch.where(torch.isfinite(target_fire), 
                                        target_fire, torch.tensor(0.0))
                
                # æ ‡å‡†åŒ–ç«ç¾çŠ¶æ€åˆ°[0,1]
                initial_fire = torch.sigmoid(initial_fire * 0.1)  # å‡å°sigmoidè¾“å…¥
                target_fire = torch.sigmoid(target_fire * 0.1)
                
                return env_features, initial_fire, target_fire
                
        except Exception as e:
            # è¿”å›é›¶å¼ é‡
            return (torch.zeros(22, *self.target_size),
                   torch.zeros(1, *self.target_size),
                   torch.zeros(1, *self.target_size))

class CATrainer:
    """CAæ¨¡å‹è®­ç»ƒå™¨"""
    
    def __init__(self, model, train_loader, val_loader, device='cpu'):
        self.model = model.to(device)
        self.train_loader = train_loader
        self.val_loader = val_loader
        self.device = device
        
        # æŸå¤±å‡½æ•°ï¼šç»„åˆæŸå¤±
        self.mse_loss = nn.MSELoss()
        self.bce_loss = nn.BCELoss()
        
        # ä¼˜åŒ–å™¨
        self.optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3, weight_decay=1e-4)
        self.scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(self.optimizer, T_max=20)
        
        # è®­ç»ƒå†å²
        self.train_losses = []
        self.val_losses = []
        self.val_auprcs = []
        self.best_val_loss = float('inf')
        
        print(f"ğŸ”¥ CAè®­ç»ƒå™¨åˆå§‹åŒ–å®Œæˆ")
        print(f"ğŸ“Š æ¨¡å‹å‚æ•°: {sum(p.numel() for p in model.parameters()):,}")
    
    def ca_loss(self, predicted_fire, target_fire, evolution_sequence=None):
        """CAä¸“ç”¨æŸå¤±å‡½æ•°"""
        # åŸºç¡€é‡å»ºæŸå¤±
        recon_loss = self.mse_loss(predicted_fire, target_fire)
        
        # äºŒå€¼åŒ–æŸå¤±ï¼ˆé¼“åŠ±æ¸…æ™°çš„çŠ¶æ€ï¼‰
        binary_target = (target_fire > 0.5).float()
        binary_loss = self.bce_loss(predicted_fire, binary_target)
        
        # å¹³æ»‘æ€§æŸå¤±ï¼ˆç›¸é‚»åƒç´ çŠ¶æ€ç›¸ä¼¼ï¼‰
        smooth_loss = 0
        if predicted_fire.size(0) > 0:
            # æ°´å¹³å¹³æ»‘
            h_smooth = torch.mean((predicted_fire[:, :, :, 1:] - predicted_fire[:, :, :, :-1])**2)
            # å‚ç›´å¹³æ»‘
            v_smooth = torch.mean((predicted_fire[:, :, 1:, :] - predicted_fire[:, :, :-1, :])**2)
            smooth_loss = (h_smooth + v_smooth) * 0.1
        
        # æ¼”åŒ–ä¸€è‡´æ€§æŸå¤±
        evolution_loss = 0
        if evolution_sequence is not None and len(evolution_sequence) > 1:
            for i in range(1, len(evolution_sequence)):
                # çŠ¶æ€è½¬ç§»åº”è¯¥åˆç†ï¼ˆç‡ƒçƒ§åŒºåŸŸä¸èƒ½çªç„¶æ¶ˆå¤±ï¼‰
                prev_state = evolution_sequence[i-1]
                curr_state = evolution_sequence[i]
                
                # å·²ç‡ƒçƒ§åŒºåŸŸåº”è¯¥ä¿æŒå·²ç‡ƒçƒ§
                burned_mask = (prev_state > 0.75)
                if burned_mask.any():
                    evolution_loss += torch.mean((curr_state[burned_mask] - 1.0)**2) * 0.1
        
        total_loss = recon_loss + binary_loss + smooth_loss + evolution_loss
        
        return total_loss, {
            'recon': recon_loss.item(),
            'binary': binary_loss.item(),
            'smooth': smooth_loss if isinstance(smooth_loss, (int, float)) else smooth_loss.item(),
            'evolution': evolution_loss if isinstance(evolution_loss, (int, float)) else evolution_loss.item()
        }
    
    def train_epoch(self, epoch):
        """è®­ç»ƒä¸€ä¸ªepoch"""
        self.model.train()
        total_loss = 0
        valid_batches = 0
        
        print_interval = max(1, len(self.train_loader) // 10)
        
        for batch_idx, (env_features, initial_fire, target_fire) in enumerate(self.train_loader):
            env_features = env_features.to(self.device)
            initial_fire = initial_fire.to(self.device)
            target_fire = target_fire.to(self.device)
            
            # æ•°æ®éªŒè¯
            if (torch.isnan(env_features).any() or torch.isnan(initial_fire).any() or 
                torch.isnan(target_fire).any()):
                continue
            
            self.optimizer.zero_grad()
            
            # CAæ¼”åŒ–
            predicted_fire, evolution_sequence = self.model(
                env_features, initial_fire, num_steps=5
            )
            
            # è®¡ç®—æŸå¤±
            loss, loss_components = self.ca_loss(predicted_fire, target_fire, evolution_sequence)
            
            if torch.isnan(loss) or torch.isinf(loss):
                continue
            
            # åå‘ä¼ æ’­
            loss.backward()
            torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=1.0)
            self.optimizer.step()
            
            total_loss += loss.item()
            valid_batches += 1
            
            # æ‰“å°è¿›åº¦
            if batch_idx % print_interval == 0:
                print(f"  Batch {batch_idx}/{len(self.train_loader)}, "
                      f"Loss: {loss.item():.6f} "
                      f"[Recon: {loss_components['recon']:.4f}, "
                      f"Binary: {loss_components['binary']:.4f}]")
        
        return total_loss / max(valid_batches, 1)
    
    def validate(self):
        """éªŒè¯"""
        self.model.eval()
        total_loss = 0
        all_preds = []
        all_targets = []
        valid_batches = 0
        
        with torch.no_grad():
            for env_features, initial_fire, target_fire in self.val_loader:
                env_features = env_features.to(self.device)
                initial_fire = initial_fire.to(self.device)
                target_fire = target_fire.to(self.device)
                
                if (torch.isnan(env_features).any() or torch.isnan(initial_fire).any() or 
                    torch.isnan(target_fire).any()):
                    continue
                
                predicted_fire, _ = self.model(env_features, initial_fire, num_steps=5)
                loss, _ = self.ca_loss(predicted_fire, target_fire)
                
                if not (torch.isnan(loss) or torch.isinf(loss)):
                    total_loss += loss.item()
                    valid_batches += 1
                    
                    all_preds.append(predicted_fire.cpu().numpy().flatten())
                    all_targets.append(target_fire.cpu().numpy().flatten())
        
        # è®¡ç®—AUPRC
        if all_preds and all_targets:
            preds = np.concatenate(all_preds)
            targets = np.concatenate(all_targets)
            targets_binary = (targets > 0.5).astype(int)
            
            try:
                auprc = average_precision_score(targets_binary, preds)
            except:
                auprc = 0.0
        else:
            auprc = 0.0
        
        return total_loss / max(valid_batches, 1), auprc
    
    def train(self, num_epochs=25):
        """å®Œæ•´è®­ç»ƒæµç¨‹"""
        print(f"ğŸš€ å¼€å§‹CAæ¨¡å‹è®­ç»ƒ {num_epochs} epochs")
        
        save_dir = Path('ca_wildfire_outputs')
        save_dir.mkdir(exist_ok=True)
        
        for epoch in range(num_epochs):
            print(f"\nğŸ”¥ Epoch {epoch+1}/{num_epochs}")
            print("-" * 50)
            
            # è®­ç»ƒå’ŒéªŒè¯
            train_loss = self.train_epoch(epoch+1)
            val_loss, val_auprc = self.validate()
            
            # å­¦ä¹ ç‡è°ƒåº¦
            self.scheduler.step()
            current_lr = self.optimizer.param_groups[0]['lr']
            
            # è®°å½•
            self.train_losses.append(train_loss)
            self.val_losses.append(val_loss)
            self.val_auprcs.append(val_auprc)
            
            print(f"ğŸ“Š Results:")
            print(f"  è®­ç»ƒæŸå¤±: {train_loss:.6f}")
            print(f"  éªŒè¯æŸå¤±: {val_loss:.6f}")
            print(f"  éªŒè¯AUPRC: {val_auprc:.4f}")
            print(f"  å­¦ä¹ ç‡: {current_lr:.2e}")
            
            # ä¿å­˜æœ€ä½³æ¨¡å‹
            if val_loss < self.best_val_loss:
                self.best_val_loss = val_loss
                torch.save({
                    'model_state_dict': self.model.state_dict(),
                    'epoch': epoch,
                    'train_loss': train_loss,
                    'val_loss': val_loss,
                    'val_auprc': val_auprc
                }, save_dir / 'best_ca_model.pth')
                print("ğŸ’¾ ä¿å­˜æœ€ä½³CAæ¨¡å‹")
        
        # ç»˜åˆ¶è®­ç»ƒæ›²çº¿
        self.plot_training_curves(save_dir)
        
        print(f"\nâœ… CAè®­ç»ƒå®Œæˆ!")
        print(f"ğŸ“ ç»“æœä¿å­˜åœ¨: {save_dir}")
        
        return self.best_val_loss
    
    def plot_training_curves(self, save_dir):
        """ç»˜åˆ¶è®­ç»ƒæ›²çº¿"""
        fig, axes = plt.subplots(1, 3, figsize=(15, 5))
        
        epochs = range(1, len(self.train_losses) + 1)
        
        # æŸå¤±æ›²çº¿
        axes[0].plot(epochs, self.train_losses, 'b-', label='è®­ç»ƒæŸå¤±', linewidth=2)
        axes[0].plot(epochs, self.val_losses, 'r-', label='éªŒè¯æŸå¤±', linewidth=2)
        axes[0].set_title('CAæ¨¡å‹æŸå¤±æ›²çº¿')
        axes[0].set_xlabel('Epoch')
        axes[0].set_ylabel('Loss')
        axes[0].legend()
        axes[0].grid(True, alpha=0.3)
        
        # AUPRCæ›²çº¿
        axes[1].plot(epochs, self.val_auprcs, 'g-', label='éªŒè¯AUPRC', linewidth=2)
        axes[1].set_title('CAæ¨¡å‹AUPRCæ›²çº¿')
        axes[1].set_xlabel('Epoch')
        axes[1].set_ylabel('AUPRC')
        axes[1].legend()
        axes[1].grid(True, alpha=0.3)
        
        # ç»Ÿè®¡ä¿¡æ¯
        best_auprc = max(self.val_auprcs) if self.val_auprcs else 0
        stats_text = f"""CAæ¨¡å‹è®­ç»ƒç»Ÿè®¡:

æœ€ä½³éªŒè¯æŸå¤±: {self.best_val_loss:.6f}
æœ€ä½³AUPRC: {best_auprc:.4f}
æ€»è®­ç»ƒè½®æ•°: {len(self.train_losses)}

æ¨¡å‹ç‰¹ç‚¹:
- åŸºäºç‰©ç†è§„åˆ™
- è€ƒè™‘é£å‘å½±å“
- çŠ¶æ€è½¬ç§»å­¦ä¹ 
- æ—¶åºæ¼”åŒ–å»ºæ¨¡"""
        
        axes[2].text(0.1, 0.5, stats_text, transform=axes[2].transAxes, fontsize=11)
        axes[2].set_title('CAæ¨¡å‹ç»Ÿè®¡')
        axes[2].axis('off')
        
        plt.tight_layout()
        plt.savefig(save_dir / 'ca_training_curves.png', dpi=300, bbox_inches='tight')
        plt.show()

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ”¥ Cellular Automata é‡ç«æ¨¡å‹")
    print("=" * 60)
    print("ğŸ§® åŸºäºç‰©ç†è§„åˆ™çš„å…ƒèƒè‡ªåŠ¨æœºé‡ç«ä¼ æ’­æ¨¡æ‹Ÿ")
    print("=" * 60)
    
    # é…ç½®
    config = {
        'data_dir': 'data/processed',
        'batch_size': 4,
        'num_epochs': 25,
        'max_files': 100,
        'target_size': (128, 128),
        'device': 'cuda' if torch.cuda.is_available() else 'cpu',
        'ca_steps': 5
    }
    
    print(f"\né…ç½®:")
    for key, value in config.items():
        print(f"  {key}: {value}")
    
    # æ£€æŸ¥æ•°æ®ç›®å½•
    data_dir = Path(config['data_dir'])
    if not data_dir.exists():
        print(f"âŒ æ•°æ®ç›®å½•ä¸å­˜åœ¨: {data_dir}")
        print("è¯·ç¡®ä¿é‡ç«æ•°æ®åœ¨ data/processed ç›®å½•ä¸‹")
        return
    
    # è®­ç»ƒå¯å­¦ä¹ CAæ¨¡å‹
    print(f"\nğŸš€ å¼€å§‹è®­ç»ƒå¯å­¦ä¹ CAæ¨¡å‹...")
    
    # åˆ›å»ºæ•°æ®é›†
    print(f"\n1. åˆ›å»ºCAæ•°æ®é›†...")
    train_dataset = CAWildfireDataset(
        config['data_dir'],
        mode='train',
        max_files=config['max_files'],
        target_size=config['target_size']
    )
    
    val_dataset = CAWildfireDataset(
        config['data_dir'],
        mode='val',
        max_files=config['max_files']//4,
        target_size=config['target_size']
    )
    
    print(f"âœ… è®­ç»ƒé›†: {len(train_dataset)} æ ·æœ¬")
    print(f"âœ… éªŒè¯é›†: {len(val_dataset)} æ ·æœ¬")
    
    if len(train_dataset) == 0:
        print("âŒ è®­ç»ƒé›†ä¸ºç©ºï¼Œè¯·æ£€æŸ¥æ•°æ®ç›®å½•å’Œæ–‡ä»¶æ ¼å¼")
        return
    
    # åˆ›å»ºæ•°æ®åŠ è½½å™¨
    train_loader = DataLoader(
        train_dataset,
        batch_size=config['batch_size'],
        shuffle=True,
        num_workers=0  # Windowså…¼å®¹
    )
    
    val_loader = DataLoader(
        val_dataset,
        batch_size=config['batch_size'],
        shuffle=False,
        num_workers=0
    )
    
    # åˆ›å»ºå¯å­¦ä¹ CAæ¨¡å‹
    print(f"\n2. åˆ›å»ºå¯å­¦ä¹ CAæ¨¡å‹...")
    ca_model = LearnableCA(
        input_channels=22,
        hidden_dim=64,
        grid_size=config['target_size']
    )
    
    # åˆ›å»ºè®­ç»ƒå™¨
    print(f"\n3. åˆ›å»ºCAè®­ç»ƒå™¨...")
    ca_trainer = CATrainer(
        model=ca_model,
        train_loader=train_loader,
        val_loader=val_loader,
        device=config['device']
    )
    
    # å¼€å§‹è®­ç»ƒ
    print(f"\n4. å¼€å§‹è®­ç»ƒ...")
    best_loss = ca_trainer.train(num_epochs=config['num_epochs'])
    
    print(f"\nâœ… å¯å­¦ä¹ CAæ¨¡å‹è®­ç»ƒå®Œæˆ!")
    print(f"ğŸ† æœ€ä½³éªŒè¯æŸå¤±: {best_loss:.6f}")
    print(f"ğŸ“ ç»“æœä¿å­˜åœ¨: ca_wildfire_outputs/")
    print(f"ğŸ’¾ æœ€ä½³æ¨¡å‹: best_ca_model.pth")
    print(f"ğŸ“Š è®­ç»ƒæ›²çº¿: ca_training_curves.png")

if __name__ == "__main__":
    # è®¾ç½®éšæœºç§å­
    np.random.seed(42)
    torch.manual_seed(42)
    
    # è¿è¡Œä¸»ç¨‹åº
    try:
        main()
    except Exception as e:
        print(f"è¿è¡Œå‡ºé”™: {e}")
        import traceback
        traceback.print_exc() 