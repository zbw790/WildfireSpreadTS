#!/usr/bin/env python3
"""
GPUåŠ é€Ÿæµ‹è¯•è„šæœ¬
"""

import torch
import time

def test_gpu_acceleration():
    """æµ‹è¯•GPUåŠ é€Ÿæ˜¯å¦å¯ç”¨"""
    
    print("ğŸ”§ GPUåŠ é€Ÿæµ‹è¯•")
    print("=" * 50)
    
    # 1. åŸºæœ¬ä¿¡æ¯
    print(f"PyTorchç‰ˆæœ¬: {torch.__version__}")
    print(f"CUDAç‰ˆæœ¬: {torch.version.cuda}")
    print(f"CUDAå¯ç”¨: {torch.cuda.is_available()}")
    
    if torch.cuda.is_available():
        print(f"GPUè®¾å¤‡æ•°é‡: {torch.cuda.device_count()}")
        for i in range(torch.cuda.device_count()):
            print(f"GPU {i}: {torch.cuda.get_device_name(i)}")
            print(f"  å†…å­˜æ€»é‡: {torch.cuda.get_device_properties(i).total_memory / (1024**3):.1f} GB")
            print(f"  è®¡ç®—èƒ½åŠ›: {torch.cuda.get_device_properties(i).major}.{torch.cuda.get_device_properties(i).minor}")
    else:
        print("âŒ CUDAä¸å¯ç”¨")
        return False
    
    # 2. æ€§èƒ½æµ‹è¯•
    print("\nğŸš€ æ€§èƒ½å¯¹æ¯”æµ‹è¯•:")
    
    # åˆ›å»ºæµ‹è¯•æ•°æ®
    size = (1000, 1000)
    cpu_tensor1 = torch.randn(size)
    cpu_tensor2 = torch.randn(size)
    
    if torch.cuda.is_available():
        gpu_tensor1 = cpu_tensor1.cuda()
        gpu_tensor2 = cpu_tensor2.cuda()
        
        # CPUæµ‹è¯•
        start_time = time.time()
        for _ in range(100):
            result_cpu = torch.mm(cpu_tensor1, cpu_tensor2)
        cpu_time = time.time() - start_time
        
        # GPUæµ‹è¯•
        torch.cuda.synchronize()  # ç¡®ä¿GPUæ“ä½œå®Œæˆ
        start_time = time.time()
        for _ in range(100):
            result_gpu = torch.mm(gpu_tensor1, gpu_tensor2)
        torch.cuda.synchronize()
        gpu_time = time.time() - start_time
        
        print(f"CPUæ—¶é—´: {cpu_time:.3f}ç§’")
        print(f"GPUæ—¶é—´: {gpu_time:.3f}ç§’")
        print(f"åŠ é€Ÿæ¯”: {cpu_time / gpu_time:.1f}x")
        
        # éªŒè¯ç»“æœä¸€è‡´æ€§
        diff = torch.abs(result_cpu - result_gpu.cpu()).max()
        print(f"ç»“æœå·®å¼‚: {diff:.6f} (åº”è¯¥å¾ˆå°)")
        
        return True
    else:
        return False

def test_cnn_on_gpu():
    """æµ‹è¯•CNNæ¨¡å‹åœ¨GPUä¸Šçš„è¿è¡Œ"""
    
    if not torch.cuda.is_available():
        print("âŒ GPUä¸å¯ç”¨ï¼Œè·³è¿‡CNNæµ‹è¯•")
        return
    
    print("\nğŸ§  CNNæ¨¡å‹GPUæµ‹è¯•:")
    
    # åˆ›å»ºç®€å•çš„CNNæ¨¡å‹
    class SimpleCNN(torch.nn.Module):
        def __init__(self):
            super().__init__()
            self.conv1 = torch.nn.Conv2d(3, 32, 3, padding=1)
            self.conv2 = torch.nn.Conv2d(32, 64, 3, padding=1)
            self.fc = torch.nn.Linear(64 * 32 * 32, 10)
            
        def forward(self, x):
            x = torch.relu(self.conv1(x))
            x = torch.relu(self.conv2(x))
            x = torch.nn.functional.adaptive_avg_pool2d(x, (32, 32))
            x = x.view(x.size(0), -1)
            x = self.fc(x)
            return x
    
    # åˆ›å»ºæ¨¡å‹å’Œæ•°æ®
    model = SimpleCNN()
    data = torch.randn(4, 3, 128, 128)  # batch_size=4, channels=3, size=128x128
    
    # CPUæµ‹è¯•
    start_time = time.time()
    with torch.no_grad():
        output_cpu = model(data)
    cpu_time = time.time() - start_time
    
    # GPUæµ‹è¯•
    model_gpu = model.cuda()
    data_gpu = data.cuda()
    
    torch.cuda.synchronize()
    start_time = time.time()
    with torch.no_grad():
        output_gpu = model_gpu(data_gpu)
    torch.cuda.synchronize()
    gpu_time = time.time() - start_time
    
    print(f"CNN CPUæ¨ç†æ—¶é—´: {cpu_time:.3f}ç§’")
    print(f"CNN GPUæ¨ç†æ—¶é—´: {gpu_time:.3f}ç§’")
    print(f"CNNåŠ é€Ÿæ¯”: {cpu_time / gpu_time:.1f}x")
    
    # éªŒè¯ç»“æœ
    diff = torch.abs(output_cpu - output_gpu.cpu()).max()
    print(f"è¾“å‡ºå·®å¼‚: {diff:.6f}")
    print("âœ… CNN GPUæµ‹è¯•æˆåŠŸ!")

if __name__ == "__main__":
    print("ğŸ”¥ é‡ç«CNN GPUåŠ é€Ÿæµ‹è¯•")
    
    # æµ‹è¯•GPUåŸºæœ¬åŠŸèƒ½
    gpu_available = test_gpu_acceleration()
    
    if gpu_available:
        # æµ‹è¯•CNNæ¨¡å‹
        test_cnn_on_gpu()
        
        print("\nğŸ‰ GPUåŠ é€Ÿæµ‹è¯•å®Œæˆ!")
        print("âœ… æ‚¨çš„ç¯å¢ƒæ”¯æŒGPUåŠ é€Ÿ")
        print("ğŸ’¡ ç°åœ¨å¯ä»¥ä½¿ç”¨GPUè®­ç»ƒé‡ç«CNNæ¨¡å‹äº†")
    else:
        print("\nâŒ GPUåŠ é€Ÿä¸å¯ç”¨")
        print("ğŸ’¡ è¯·å®‰è£…GPUç‰ˆæœ¬çš„PyTorch:")
        print("   pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121") 