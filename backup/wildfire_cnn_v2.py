#!/usr/bin/env python3
"""
WildfireSpreadTS CNNæ¨¡å‹ v2.0
å®Œæ•´çš„é‡ç«ä¼ æ’­é¢„æµ‹æ·±åº¦å­¦ä¹ ç³»ç»Ÿ

ç‰¹ç‚¹:
- å¤„ç†æ‰€æœ‰607ä¸ªç«ç¾äº‹ä»¶
- U-Netæ¶æ„é€‚åˆåˆ†å‰²ä»»åŠ¡
- Focal Losså¤„ç†ç±»åˆ«ä¸å¹³è¡¡
- å®Œæ•´çš„è®­ç»ƒ/éªŒè¯ç®¡é“
- æ”¯æŒæ—¶ç©ºåºåˆ—é¢„æµ‹

ä½œè€…: AI Assistant
æ—¥æœŸ: 2025-01-30
"""

import os
import numpy as np
import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler
from torch.optim import AdamW
from torch.optim.lr_scheduler import ReduceLROnPlateau
import h5py
from pathlib import Path
import json
import time
from datetime import datetime
import matplotlib.pyplot as plt
from sklearn.metrics import average_precision_score, f1_score, precision_score, recall_score
from sklearn.preprocessing import RobustScaler
import warnings
warnings.filterwarnings('ignore')

# ================================
# 1. æ•°æ®åŠ è½½å™¨
# ================================

class WildfireDataset(Dataset):
    """é‡ç«æ•°æ®é›†ç±»"""
    
    def __init__(self, data_dir, sequence_length=5, prediction_horizon=1, 
                 train_split=0.8, mode='train', normalize=True):
        """
        Args:
            data_dir: HDF5æ–‡ä»¶ç›®å½•
            sequence_length: è¾“å…¥æ—¶é—´åºåˆ—é•¿åº¦ 
            prediction_horizon: é¢„æµ‹æ—¶é—´æ­¥æ•°
            train_split: è®­ç»ƒé›†æ¯”ä¾‹
            mode: 'train', 'val', 'test'
            normalize: æ˜¯å¦æ ‡å‡†åŒ–
        """
        self.data_dir = Path(data_dir)
        self.sequence_length = sequence_length
        self.prediction_horizon = prediction_horizon
        self.mode = mode
        self.normalize = normalize
        
        # æ‰¾åˆ°æ‰€æœ‰HDF5æ–‡ä»¶
        self.hdf5_files = []
        for year in ['2018', '2019', '2020', '2021']:
            year_dir = self.data_dir / year
            if year_dir.exists():
                year_files = list(year_dir.glob("*.hdf5"))
                self.hdf5_files.extend(year_files)
        
        print(f"å‘ç° {len(self.hdf5_files)} ä¸ªHDF5æ–‡ä»¶")
        
        # æŒ‰æ¨¡å¼åˆ†å‰²æ–‡ä»¶
        n_files = len(self.hdf5_files)
        train_end = int(n_files * train_split)
        val_end = int(n_files * (train_split + 0.1))
        
        if mode == 'train':
            self.files = self.hdf5_files[:train_end]
        elif mode == 'val':
            self.files = self.hdf5_files[train_end:val_end] 
        else:  # test
            self.files = self.hdf5_files[val_end:]
        
        print(f"{mode}æ¨¡å¼: {len(self.files)} ä¸ªæ–‡ä»¶")
        
        # æ„å»ºæ ·æœ¬ç´¢å¼•
        self.samples = []
        self._build_samples()
        
        # åˆå§‹åŒ–æ ‡å‡†åŒ–å™¨
        if self.normalize and mode == 'train':
            self._initialize_normalizer()
    
    def _build_samples(self):
        """æ„å»ºæ‰€æœ‰å¯ç”¨çš„æ ·æœ¬ç´¢å¼•"""
        print(f"æ„å»º{self.mode}æ ·æœ¬ç´¢å¼•...")
        
        for file_idx, file_path in enumerate(self.files):
            try:
                with h5py.File(file_path, 'r') as f:
                    data = f['data']
                    n_timesteps = data.shape[0]
                    
                    # è®¡ç®—å¯ç”¨çš„æ ·æœ¬æ•°é‡
                    max_start = n_timesteps - self.sequence_length - self.prediction_horizon + 1
                    
                    if max_start > 0:
                        for start_idx in range(0, max_start, 2):  # æ¯2æ­¥é‡‡æ ·ä¸€æ¬¡
                            self.samples.append((file_idx, start_idx))
                            
            except Exception as e:
                print(f"å¤„ç†æ–‡ä»¶ {file_path} æ—¶å‡ºé”™: {e}")
                continue
        
        print(f"æ€»è®¡ {len(self.samples)} ä¸ªæ ·æœ¬")
    
    def _initialize_normalizer(self):
        """åˆå§‹åŒ–æ•°æ®æ ‡å‡†åŒ–å™¨"""
        print("åˆå§‹åŒ–æ•°æ®æ ‡å‡†åŒ–å™¨...")
        
        # é‡‡æ ·ä¸€äº›æ•°æ®æ¥è®¡ç®—ç»Ÿè®¡é‡
        sample_data = []
        n_samples = min(1000, len(self.samples))
        
        for i in range(0, n_samples, 10):
            try:
                sample = self[i]
                if sample is not None:
                    features = sample[0]  # (T, C, H, W)
                    # æ’é™¤åœŸåœ°è¦†ç›–ç±»åˆ«ç‰¹å¾ (channel 16)
                    mask = torch.ones(features.shape[1], dtype=torch.bool)
                    mask[16] = False
                    continuous_features = features[:, mask, :, :]
                    sample_data.append(continuous_features.numpy().flatten())
            except:
                continue
        
        if sample_data:
            all_data = np.concatenate(sample_data)
            self.scaler = RobustScaler()
            self.scaler.fit(all_data.reshape(-1, 1))
            print("æ ‡å‡†åŒ–å™¨åˆå§‹åŒ–å®Œæˆ")
        else:
            self.scaler = None
            print("è­¦å‘Š: æ— æ³•åˆå§‹åŒ–æ ‡å‡†åŒ–å™¨")
    
    def __len__(self):
        return len(self.samples)
    
    def __getitem__(self, idx):
        """è·å–å•ä¸ªæ ·æœ¬"""
        file_idx, start_idx = self.samples[idx]
        file_path = self.files[file_idx]
        
        try:
            with h5py.File(file_path, 'r') as f:
                data = f['data']  # (T, C, H, W)
                
                # æå–è¾“å…¥åºåˆ—å’Œç›®æ ‡
                end_idx = start_idx + self.sequence_length
                target_idx = end_idx + self.prediction_horizon - 1
                
                input_sequence = torch.from_numpy(data[start_idx:end_idx]).float()
                target = torch.from_numpy(data[target_idx, 22:23]).float()  # ç«ç‚¹ç½®ä¿¡åº¦é€šé“
                
                # æ•°æ®é¢„å¤„ç†
                input_sequence = self._preprocess_features(input_sequence)
                target = self._preprocess_target(target)
                
                return input_sequence, target
                
        except Exception as e:
            print(f"åŠ è½½æ ·æœ¬ {idx} æ—¶å‡ºé”™: {e}")
            # è¿”å›éšæœºæ ·æœ¬
            if len(self.samples) > 1:
                return self[(idx + 1) % len(self.samples)]
            else:
                return None
    
    def _preprocess_features(self, features):
        """é¢„å¤„ç†è¾“å…¥ç‰¹å¾"""
        # features: (T, C, H, W)
        
        # 0. Resizeåˆ°å›ºå®šå°ºå¯¸ (è§£å†³ä¸åŒç«ç¾äº‹ä»¶å°ºå¯¸ä¸ä¸€è‡´é—®é¢˜)
        target_size = (256, 256)  # å›ºå®šå°ºå¯¸
        features = F.interpolate(features, size=target_size, mode='bilinear', align_corners=False)
        
        # 1. å¤„ç†åœŸåœ°è¦†ç›–ç±»åˆ«ç‰¹å¾ (channel 16)
        landcover = features[:, 16:17, :, :].clone()
        landcover = torch.clamp(landcover, 1, 16) - 1  # è½¬æ¢ä¸º0-15èŒƒå›´
        
        # 2. æ ‡å‡†åŒ–è¿ç»­ç‰¹å¾
        continuous_features = torch.cat([
            features[:, :16, :, :], 
            features[:, 17:, :, :]
        ], dim=1)
        
        if hasattr(self, 'scaler') and self.scaler is not None:
            original_shape = continuous_features.shape
            continuous_features = continuous_features.view(-1, 1)
            continuous_features = torch.from_numpy(
                self.scaler.transform(continuous_features.numpy())
            ).float()
            continuous_features = continuous_features.view(original_shape)
        
        # 3. é‡æ–°ç»„åˆç‰¹å¾
        processed_features = torch.cat([
            continuous_features[:, :16, :, :],
            landcover,
            continuous_features[:, 16:, :, :]
        ], dim=1)
        
        return processed_features
    
    def _preprocess_target(self, target):
        """é¢„å¤„ç†ç›®æ ‡å˜é‡"""
        # target: (1, H, W)
        
        # 0. Resizeåˆ°å›ºå®šå°ºå¯¸
        target_size = (256, 256)
        target = F.interpolate(target.unsqueeze(0), size=target_size, mode='bilinear', align_corners=False)
        target = target.squeeze(0)
        
        # 1. å°†ç›®æ ‡è½¬æ¢ä¸ºäºŒå€¼åŒ– (>0 ä¸ºç«ç‚¹)
        target = (target > 0).float()
        return target


# ================================
# 2. CNNæ¨¡å‹æ¶æ„
# ================================

class ConvBlock(nn.Module):
    """å·ç§¯å—"""
    def __init__(self, in_channels, out_channels):
        super().__init__()
        self.conv = nn.Sequential(
            nn.Conv2d(in_channels, out_channels, 3, padding=1),
            nn.BatchNorm2d(out_channels),
            nn.ReLU(inplace=True),
            nn.Conv2d(out_channels, out_channels, 3, padding=1),
            nn.BatchNorm2d(out_channels),
            nn.ReLU(inplace=True)
        )
    
    def forward(self, x):
        return self.conv(x)

class WildfireCNN(nn.Module):
    """é‡ç«é¢„æµ‹CNNæ¨¡å‹ - ç®€åŒ–çš„U-Netæ¶æ„"""
    
    def __init__(self, input_channels=23, sequence_length=5, base_channels=32):
        super().__init__()
        
        self.sequence_length = sequence_length
        self.input_channels = input_channels
        
        # åœŸåœ°è¦†ç›–åµŒå…¥å±‚
        self.landcover_embedding = nn.Embedding(16, 8)  # 16ç±» -> 8ç»´
        
        # è®¡ç®—å®é™…è¾“å…¥é€šé“æ•° (è¿ç»­ç‰¹å¾ + åµŒå…¥ç‰¹å¾)
        continuous_channels = input_channels - 1  # æ’é™¤åœŸåœ°è¦†ç›–
        embedded_channels = continuous_channels + 8  # åŠ ä¸ŠåµŒå…¥ç»´åº¦
        total_input_channels = embedded_channels * sequence_length
        
        # U-Netç¼–ç å™¨
        self.encoder1 = ConvBlock(total_input_channels, base_channels)
        self.pool1 = nn.MaxPool2d(2)
        
        self.encoder2 = ConvBlock(base_channels, base_channels * 2)
        self.pool2 = nn.MaxPool2d(2)
        
        self.encoder3 = ConvBlock(base_channels * 2, base_channels * 4)
        self.pool3 = nn.MaxPool2d(2)
        
        # ç“¶é¢ˆå±‚
        self.bottleneck = ConvBlock(base_channels * 4, base_channels * 8)
        
        # U-Netè§£ç å™¨
        self.upconv3 = nn.ConvTranspose2d(base_channels * 8, base_channels * 4, 2, stride=2)
        self.decoder3 = ConvBlock(base_channels * 8, base_channels * 4)
        
        self.upconv2 = nn.ConvTranspose2d(base_channels * 4, base_channels * 2, 2, stride=2)
        self.decoder2 = ConvBlock(base_channels * 4, base_channels * 2)
        
        self.upconv1 = nn.ConvTranspose2d(base_channels * 2, base_channels, 2, stride=2)
        self.decoder1 = ConvBlock(base_channels * 2, base_channels)
        
        # è¾“å‡ºå±‚
        self.output = nn.Sequential(
            nn.Conv2d(base_channels, 1, 1),
            nn.Sigmoid()
        )
        
        # Dropout
        self.dropout = nn.Dropout2d(0.3)
    
    def forward(self, x):
        # x: (B, T, C, H, W)
        batch_size = x.size(0)
        
        # å¤„ç†æ—¶é—´åºåˆ—
        processed_frames = []
        
        for t in range(self.sequence_length):
            frame = x[:, t]  # (B, C, H, W)
            
            # åˆ†ç¦»åœŸåœ°è¦†ç›–å’Œè¿ç»­ç‰¹å¾
            landcover = frame[:, 16].long()  # (B, H, W)
            continuous = torch.cat([frame[:, :16], frame[:, 17:]], dim=1)  # (B, 22, H, W)
            
            # åµŒå…¥åœŸåœ°è¦†ç›–
            landcover_embedded = self.landcover_embedding(landcover)  # (B, H, W, 8)
            landcover_embedded = landcover_embedded.permute(0, 3, 1, 2)  # (B, 8, H, W)
            
            # ç»„åˆç‰¹å¾
            combined = torch.cat([continuous, landcover_embedded], dim=1)  # (B, 30, H, W)
            processed_frames.append(combined)
        
        # è¿æ¥æ‰€æœ‰æ—¶é—´æ­¥
        x = torch.cat(processed_frames, dim=1)  # (B, T*30, H, W)
        
        # U-Netå‰å‘ä¼ æ’­
        # ç¼–ç å™¨
        e1 = self.encoder1(x)
        p1 = self.pool1(e1)
        
        e2 = self.encoder2(p1)
        p2 = self.pool2(e2)
        
        e3 = self.encoder3(p2)
        p3 = self.pool3(e3)
        
        # ç“¶é¢ˆ
        b = self.bottleneck(p3)
        b = self.dropout(b)
        
        # è§£ç å™¨
        up3 = self.upconv3(b)
        merge3 = torch.cat([up3, e3], dim=1)
        d3 = self.decoder3(merge3)
        
        up2 = self.upconv2(d3)
        merge2 = torch.cat([up2, e2], dim=1)
        d2 = self.decoder2(merge2)
        
        up1 = self.upconv1(d2)
        merge1 = torch.cat([up1, e1], dim=1)
        d1 = self.decoder1(merge1)
        
        # è¾“å‡º
        output = self.output(d1)
        
        return output


# ================================
# 3. æŸå¤±å‡½æ•°
# ================================

class FocalLoss(nn.Module):
    """Focal Lossç”¨äºå¤„ç†ç±»åˆ«ä¸å¹³è¡¡"""
    
    def __init__(self, alpha=0.25, gamma=2.0, reduction='mean'):
        super().__init__()
        self.alpha = alpha
        self.gamma = gamma
        self.reduction = reduction
    
    def forward(self, pred, target):
        # pred: (B, 1, H, W), target: (B, 1, H, W)
        pred = pred.view(-1)
        target = target.view(-1)
        
        # ç¡®ä¿predåœ¨[0,1]èŒƒå›´å†…
        pred = torch.clamp(pred, 0.0001, 0.9999)
        
        # è®¡ç®—BCE
        bce_loss = F.binary_cross_entropy(pred, target, reduction='none')
        
        # è®¡ç®—pt
        pt = torch.where(target == 1, pred, 1 - pred)
        
        # è®¡ç®—alpha_t
        alpha_t = torch.where(target == 1, self.alpha, 1 - self.alpha)
        
        # è®¡ç®—focalæƒé‡
        focal_weight = alpha_t * (1 - pt) ** self.gamma
        
        # åº”ç”¨focalæƒé‡
        focal_loss = focal_weight * bce_loss
        
        if self.reduction == 'mean':
            return focal_loss.mean()
        elif self.reduction == 'sum':
            return focal_loss.sum()
        else:
            return focal_loss


# ================================
# 4. è®­ç»ƒå™¨
# ================================

class WildfireTrainer:
    """é‡ç«CNNè®­ç»ƒå™¨"""
    
    def __init__(self, model, train_loader, val_loader, device='cuda'):
        self.model = model.to(device)
        self.train_loader = train_loader
        self.val_loader = val_loader
        self.device = device
        
        # æŸå¤±å‡½æ•°å’Œä¼˜åŒ–å™¨
        self.criterion = FocalLoss(alpha=0.25, gamma=2.0)
        self.optimizer = AdamW(model.parameters(), lr=1e-3, weight_decay=1e-4)
        self.scheduler = ReduceLROnPlateau(self.optimizer, patience=5, factor=0.5)
        
        # è®­ç»ƒå†å²
        self.train_losses = []
        self.val_losses = []
        self.val_metrics = []
        
        # æœ€ä½³æ¨¡å‹
        self.best_val_loss = float('inf')
        self.best_model_state = None
    
    def train_epoch(self):
        """è®­ç»ƒä¸€ä¸ªepoch"""
        self.model.train()
        total_loss = 0
        n_batches = 0
        
        for batch_idx, (data, target) in enumerate(self.train_loader):
            if data is None or target is None:
                continue
                
            data, target = data.to(self.device), target.to(self.device)
            
            # å‰å‘ä¼ æ’­
            self.optimizer.zero_grad()
            output = self.model(data)
            
            # Debug: æ£€æŸ¥è¾“å‡ºèŒƒå›´
            if batch_idx == 0:
                print(f"  Debug - Output range: [{output.min().item():.6f}, {output.max().item():.6f}]")
                print(f"  Debug - Target range: [{target.min().item():.6f}, {target.max().item():.6f}]")
                print(f"  Debug - Output shape: {output.shape}, Target shape: {target.shape}")
            
            loss = self.criterion(output, target)
            
            # åå‘ä¼ æ’­
            loss.backward()
            torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=1.0)
            self.optimizer.step()
            
            total_loss += loss.item()
            n_batches += 1
            
            if batch_idx % 10 == 0:
                print(f'  Batch {batch_idx}/{len(self.train_loader)}, Loss: {loss.item():.6f}')
        
        return total_loss / n_batches if n_batches > 0 else 0
    
    def validate_epoch(self):
        """éªŒè¯ä¸€ä¸ªepoch"""
        self.model.eval()
        total_loss = 0
        all_preds = []
        all_targets = []
        
        with torch.no_grad():
            for data, target in self.val_loader:
                if data is None or target is None:
                    continue
                    
                data, target = data.to(self.device), target.to(self.device)
                
                output = self.model(data)
                loss = self.criterion(output, target)
                
                total_loss += loss.item()
                
                # æ”¶é›†é¢„æµ‹ç»“æœ
                all_preds.append(output.cpu().numpy().flatten())
                all_targets.append(target.cpu().numpy().flatten())
        
        # è®¡ç®—æŒ‡æ ‡
        if all_preds and all_targets:
            preds = np.concatenate(all_preds)
            targets = np.concatenate(all_targets)
            
            # è®¡ç®—AUPRC
            try:
                auprc = average_precision_score(targets, preds)
            except:
                auprc = 0.0
            
            # è®¡ç®—å…¶ä»–æŒ‡æ ‡ (ä½¿ç”¨é˜ˆå€¼0.5)
            pred_binary = (preds > 0.5).astype(int)
            try:
                f1 = f1_score(targets, pred_binary, zero_division=0)
                precision = precision_score(targets, pred_binary, zero_division=0)
                recall = recall_score(targets, pred_binary, zero_division=0)
            except:
                f1 = precision = recall = 0.0
            
            metrics = {
                'auprc': auprc,
                'f1': f1,
                'precision': precision,
                'recall': recall
            }
        else:
            metrics = {'auprc': 0, 'f1': 0, 'precision': 0, 'recall': 0}
        
        avg_loss = total_loss / len(self.val_loader) if len(self.val_loader) > 0 else 0
        return avg_loss, metrics
    
    def train(self, num_epochs=50, save_dir='wildfire_cnn_outputs'):
        """å®Œæ•´è®­ç»ƒæµç¨‹"""
        save_dir = Path(save_dir)
        save_dir.mkdir(exist_ok=True)
        
        print(f"å¼€å§‹è®­ç»ƒ {num_epochs} ä¸ªepochs...")
        print(f"æ¨¡å‹å°†ä¿å­˜åˆ°: {save_dir.absolute()}")
        
        start_time = time.time()
        
        for epoch in range(num_epochs):
            epoch_start = time.time()
            
            print(f"\nEpoch {epoch+1}/{num_epochs}")
            print("-" * 50)
            
            # è®­ç»ƒ
            train_loss = self.train_epoch()
            
            # éªŒè¯
            val_loss, val_metrics = self.validate_epoch()
            
            # æ›´æ–°å­¦ä¹ ç‡
            self.scheduler.step(val_loss)
            
            # è®°å½•å†å²
            self.train_losses.append(train_loss)
            self.val_losses.append(val_loss)
            self.val_metrics.append(val_metrics)
            
            # ä¿å­˜æœ€ä½³æ¨¡å‹
            if val_loss < self.best_val_loss:
                self.best_val_loss = val_loss
                self.best_model_state = self.model.state_dict().copy()
                
                # ä¿å­˜æœ€ä½³æ¨¡å‹
                torch.save({
                    'model_state_dict': self.best_model_state,
                    'epoch': epoch,
                    'val_loss': val_loss,
                    'val_metrics': val_metrics
                }, save_dir / 'best_model.pth')
            
            # æ‰“å°è¿›åº¦
            epoch_time = time.time() - epoch_start
            print(f"è®­ç»ƒæŸå¤±: {train_loss:.6f}")
            print(f"éªŒè¯æŸå¤±: {val_loss:.6f}")
            print(f"éªŒè¯AUPRC: {val_metrics['auprc']:.4f}")
            print(f"éªŒè¯F1: {val_metrics['f1']:.4f}")
            print(f"Epochæ—¶é—´: {epoch_time:.1f}s")
            
            # æ¯10ä¸ªepochä¿å­˜ä¸€æ¬¡checkpoint
            if (epoch + 1) % 10 == 0:
                torch.save({
                    'model_state_dict': self.model.state_dict(),
                    'optimizer_state_dict': self.optimizer.state_dict(),
                    'epoch': epoch,
                    'train_losses': self.train_losses,
                    'val_losses': self.val_losses,
                    'val_metrics': self.val_metrics
                }, save_dir / f'checkpoint_epoch_{epoch+1}.pth')
        
        total_time = time.time() - start_time
        print(f"\nè®­ç»ƒå®Œæˆ! æ€»æ—¶é—´: {total_time/3600:.2f}å°æ—¶")
        print(f"æœ€ä½³éªŒè¯æŸå¤±: {self.best_val_loss:.6f}")
        
        # ç»˜åˆ¶è®­ç»ƒæ›²çº¿
        self.plot_training_curves(save_dir)
        
        # ä¿å­˜è®­ç»ƒå†å²
        with open(save_dir / 'training_history.json', 'w') as f:
            json.dump({
                'train_losses': self.train_losses,
                'val_losses': self.val_losses,
                'val_metrics': self.val_metrics,
                'best_val_loss': self.best_val_loss
            }, f, indent=2)
    
    def plot_training_curves(self, save_dir):
        """ç»˜åˆ¶è®­ç»ƒæ›²çº¿"""
        fig, axes = plt.subplots(2, 2, figsize=(12, 8))
        
        epochs = range(1, len(self.train_losses) + 1)
        
        # æŸå¤±æ›²çº¿
        axes[0,0].plot(epochs, self.train_losses, label='è®­ç»ƒæŸå¤±')
        axes[0,0].plot(epochs, self.val_losses, label='éªŒè¯æŸå¤±')
        axes[0,0].set_title('æŸå¤±æ›²çº¿')
        axes[0,0].set_xlabel('Epoch')
        axes[0,0].set_ylabel('Loss')
        axes[0,0].legend()
        axes[0,0].grid(True)
        
        # AUPRCæ›²çº¿
        auprc_values = [m['auprc'] for m in self.val_metrics]
        axes[0,1].plot(epochs, auprc_values, label='éªŒè¯AUPRC', color='green')
        axes[0,1].set_title('AUPRCæ›²çº¿')
        axes[0,1].set_xlabel('Epoch')
        axes[0,1].set_ylabel('AUPRC')
        axes[0,1].legend()
        axes[0,1].grid(True)
        
        # F1æ›²çº¿
        f1_values = [m['f1'] for m in self.val_metrics]
        axes[1,0].plot(epochs, f1_values, label='éªŒè¯F1', color='orange')
        axes[1,0].set_title('F1åˆ†æ•°æ›²çº¿')
        axes[1,0].set_xlabel('Epoch')
        axes[1,0].set_ylabel('F1 Score')
        axes[1,0].legend()
        axes[1,0].grid(True)
        
        # ç²¾ç¡®ç‡å’Œå¬å›ç‡
        precision_values = [m['precision'] for m in self.val_metrics]
        recall_values = [m['recall'] for m in self.val_metrics]
        axes[1,1].plot(epochs, precision_values, label='ç²¾ç¡®ç‡', color='red')
        axes[1,1].plot(epochs, recall_values, label='å¬å›ç‡', color='blue')
        axes[1,1].set_title('ç²¾ç¡®ç‡å’Œå¬å›ç‡')
        axes[1,1].set_xlabel('Epoch')
        axes[1,1].set_ylabel('Score')
        axes[1,1].legend()
        axes[1,1].grid(True)
        
        plt.tight_layout()
        plt.savefig(save_dir / 'training_curves.png', dpi=300, bbox_inches='tight')
        plt.show()


# ================================
# 5. ä¸»è®­ç»ƒå‡½æ•°
# ================================

def main():
    """ä¸»è®­ç»ƒå‡½æ•°"""
    print("ğŸ”¥ WildfireSpreadTS CNNæ¨¡å‹è®­ç»ƒç³»ç»Ÿ v2.0")
    print("=" * 60)
    
    # é…ç½®
    config = {
        'data_dir': 'data/processed',
        'sequence_length': 5,
        'prediction_horizon': 1,
        'batch_size': 2,  # å‡å°batch_sizeé€‚åº”256x256å›¾åƒ
        'num_epochs': 50,
        'base_channels': 32,
        'num_workers': 0,  # è®¾ç½®ä¸º0é¿å…multiprocessingé—®é¢˜
        'device': 'cuda' if torch.cuda.is_available() else 'cpu'
    }
    
    print(f"é…ç½®: {json.dumps(config, indent=2)}")
    print(f"ä½¿ç”¨è®¾å¤‡: {config['device']}")
    
    # æ£€æŸ¥æ•°æ®ç›®å½•
    data_dir = Path(config['data_dir'])
    if not data_dir.exists():
        print(f"âŒ æ•°æ®ç›®å½•ä¸å­˜åœ¨: {data_dir}")
        return
    
    # åˆ›å»ºæ•°æ®é›†
    print("\n1. åˆ›å»ºæ•°æ®é›†...")
    train_dataset = WildfireDataset(
        data_dir=config['data_dir'],
        sequence_length=config['sequence_length'],
        prediction_horizon=config['prediction_horizon'],
        mode='train',
        normalize=True
    )
    
    val_dataset = WildfireDataset(
        data_dir=config['data_dir'],
        sequence_length=config['sequence_length'],
        prediction_horizon=config['prediction_horizon'],
        mode='val',
        normalize=True
    )
    
    # å¤åˆ¶è®­ç»ƒé›†çš„æ ‡å‡†åŒ–å™¨åˆ°éªŒè¯é›†
    if hasattr(train_dataset, 'scaler'):
        val_dataset.scaler = train_dataset.scaler
    
    print(f"è®­ç»ƒé›†æ ·æœ¬æ•°: {len(train_dataset)}")
    print(f"éªŒè¯é›†æ ·æœ¬æ•°: {len(val_dataset)}")
    
    # åˆ›å»ºæ•°æ®åŠ è½½å™¨
    print("\n2. åˆ›å»ºæ•°æ®åŠ è½½å™¨...")
    train_loader = DataLoader(
        train_dataset,
        batch_size=config['batch_size'],
        shuffle=True,
        num_workers=config['num_workers'],
        pin_memory=True
    )
    
    val_loader = DataLoader(
        val_dataset,
        batch_size=config['batch_size'],
        shuffle=False,
        num_workers=config['num_workers'],
        pin_memory=True
    )
    
    # åˆ›å»ºæ¨¡å‹
    print("\n3. åˆ›å»ºæ¨¡å‹...")
    model = WildfireCNN(
        input_channels=23,
        sequence_length=config['sequence_length'],
        base_channels=config['base_channels']
    )
    
    # è®¡ç®—æ¨¡å‹å‚æ•°æ•°é‡
    total_params = sum(p.numel() for p in model.parameters())
    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
    print(f"æ¨¡å‹å‚æ•°æ€»æ•°: {total_params:,}")
    print(f"å¯è®­ç»ƒå‚æ•°: {trainable_params:,}")
    
    # åˆ›å»ºè®­ç»ƒå™¨
    print("\n4. åˆ›å»ºè®­ç»ƒå™¨...")
    trainer = WildfireTrainer(
        model=model,
        train_loader=train_loader,
        val_loader=val_loader,
        device=config['device']
    )
    
    # å¼€å§‹è®­ç»ƒ
    print("\n5. å¼€å§‹è®­ç»ƒ...")
    trainer.train(
        num_epochs=config['num_epochs'],
        save_dir='wildfire_cnn_v2_outputs'
    )
    
    print("\nâœ… è®­ç»ƒå®Œæˆ!")
    print("ğŸ“ ç»“æœä¿å­˜åœ¨: wildfire_cnn_v2_outputs/")
    print("ğŸ“Š æœ€ä½³æ¨¡å‹: best_model.pth")
    print("ğŸ“ˆ è®­ç»ƒæ›²çº¿: training_curves.png")


if __name__ == "__main__":
    main() 