#!/usr/bin/env python3
"""
ä¼˜åŒ–ç‰ˆCAé‡ç«æ¨¡å‹
é’ˆå¯¹æ€§èƒ½é—®é¢˜è¿›è¡Œæ”¹è¿›ï¼š
1. ç®€åŒ–æ¶æ„å‡å°‘è¿‡æ‹Ÿåˆ
2. æ”¹è¿›æŸå¤±å‡½æ•°
3. æ›´å¥½çš„æ•°æ®å¢å¼º
4. åŠ¨æ€å­¦ä¹ ç‡
"""

import numpy as np
import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import Dataset, DataLoader
import matplotlib.pyplot as plt
from pathlib import Path
import h5py
from sklearn.metrics import average_precision_score
import warnings
warnings.filterwarnings('ignore')

class OptimizedCAModel(nn.Module):
    """ä¼˜åŒ–çš„CAæ¨¡å‹ - æ›´ç®€å•ä½†æ›´æœ‰æ•ˆ"""
    
    def __init__(self, input_channels=22, hidden_dim=32):
        super().__init__()
        
        self.input_channels = input_channels
        self.hidden_dim = hidden_dim
        
        # ç®€åŒ–çš„ç‰¹å¾ç¼–ç å™¨
        self.feature_encoder = nn.Sequential(
            nn.Conv2d(input_channels, hidden_dim, 3, padding=1),
            nn.BatchNorm2d(hidden_dim),
            nn.ReLU(inplace=True),
            nn.Dropout2d(0.1),
            
            nn.Conv2d(hidden_dim, hidden_dim, 3, padding=1),
            nn.BatchNorm2d(hidden_dim),
            nn.ReLU(inplace=True)
        )
        
        # CAæ ¸å¿ƒç½‘ç»œ - æ›´ç®€å•çš„æ¶æ„
        self.ca_core = nn.Sequential(
            nn.Conv2d(hidden_dim + 1, hidden_dim//2, 3, padding=1),  # +1 for current fire state
            nn.BatchNorm2d(hidden_dim//2),
            nn.ReLU(inplace=True),
            nn.Dropout2d(0.2),
            
            nn.Conv2d(hidden_dim//2, hidden_dim//4, 3, padding=1),
            nn.BatchNorm2d(hidden_dim//4),
            nn.ReLU(inplace=True),
            
            nn.Conv2d(hidden_dim//4, 1, 1),  # è¾“å‡ºç«åŠ¿å˜åŒ–
            nn.Sigmoid()
        )
        
        # é£å‘å½±å“ç½‘ç»œ - ç®€åŒ–ç‰ˆ
        self.wind_net = nn.Sequential(
            nn.Conv2d(2, 8, 3, padding=1),  # é£é€Ÿ+é£å‘
            nn.ReLU(inplace=True),
            nn.Conv2d(8, 1, 3, padding=1),
            nn.Sigmoid()
        )
        
        # åˆå§‹åŒ–æƒé‡
        self._init_weights()
    
    def _init_weights(self):
        for m in self.modules():
            if isinstance(m, nn.Conv2d):
                nn.init.kaiming_normal_(m.weight, mode='fan_out')
                if m.bias is not None:
                    nn.init.constant_(m.bias, 0)
            elif isinstance(m, nn.BatchNorm2d):
                nn.init.constant_(m.weight, 1)
                nn.init.constant_(m.bias, 0)
    
    def forward(self, env_features, initial_fire_state, num_steps=3):
        """ç®€åŒ–çš„å‰å‘ä¼ æ’­"""
        batch_size = env_features.size(0)
        
        # ç¼–ç ç¯å¢ƒç‰¹å¾
        env_encoded = self.feature_encoder(env_features)
        
        # æå–é£å‘ä¿¡æ¯
        wind_features = env_features[:, 7:9]  # é£å‘å’Œé£é€Ÿ
        wind_influence = self.wind_net(wind_features)
        
        # CAæ¼”åŒ–
        fire_state = initial_fire_state.clone()
        
        for step in range(num_steps):
            # å‡†å¤‡è¾“å…¥
            ca_input = torch.cat([env_encoded, fire_state], dim=1)
            
            # CAæ›´æ–°
            fire_change = self.ca_core(ca_input)
            
            # åº”ç”¨é£å‘å½±å“
            fire_change = fire_change * (1 + wind_influence * 0.5)
            
            # æ›´æ–°ç«åŠ¿çŠ¶æ€ - ç®€å•çš„åŠ æ³•æ›´æ–°
            fire_state = torch.clamp(fire_state + fire_change * 0.3, 0, 1)
        
        return fire_state

class FocalLoss(nn.Module):
    """æ”¹è¿›çš„Focal Loss"""
    
    def __init__(self, alpha=0.8, gamma=2.0):  # å¢å¤§alphaå¤„ç†ä¸å¹³è¡¡
        super().__init__()
        self.alpha = alpha
        self.gamma = gamma
    
    def forward(self, pred, target):
        pred = pred.view(-1)
        target = target.view(-1)
        
        # BCEæŸå¤±
        bce = F.binary_cross_entropy(pred, target, reduction='none')
        
        # pt
        pt = torch.where(target == 1, pred, 1 - pred)
        
        # alphaæƒé‡
        alpha_t = torch.where(target == 1, self.alpha, 1 - self.alpha)
        
        # focalæƒé‡
        focal_weight = alpha_t * (1 - pt) ** self.gamma
        
        return (focal_weight * bce).mean()

class EnhancedDataset(Dataset):
    """å¢å¼ºç‰ˆæ•°æ®é›† - æ›´å¥½çš„æ•°æ®å¢å¼º"""
    
    def __init__(self, data_dir, mode='train', max_files=100, target_size=(128, 128)):
        self.data_dir = Path(data_dir)
        self.mode = mode
        self.target_size = target_size
        self.training = (mode == 'train')
        
        print(f"ğŸ”¥ åˆå§‹åŒ–å¢å¼ºç‰ˆCAæ•°æ®é›† ({mode}æ¨¡å¼)")
        
        # æ”¶é›†æ–‡ä»¶
        self._collect_files(max_files)
        
        # æ„å»ºæ ·æœ¬
        self.samples = []
        self._build_samples()
        
        # è®¡ç®—æ•°æ®ç»Ÿè®¡
        if mode == 'train':
            self._compute_stats()
        
        print(f"âœ… æ•°æ®é›†åˆå§‹åŒ–å®Œæˆ: {len(self)} ä¸ªæ ·æœ¬")
    
    def _collect_files(self, max_files):
        all_files = []
        for year in ['2018', '2019', '2020', '2021']:
            year_dir = self.data_dir / year
            if year_dir.exists():
                year_files = list(year_dir.glob("*.hdf5"))
                all_files.extend(year_files)
        
        files_to_use = all_files[:max_files]
        n_files = len(files_to_use)
        
        if self.mode == 'train':
            self.files = files_to_use[:int(0.8 * n_files)]
        else:
            self.files = files_to_use[int(0.8 * n_files):]
        
        print(f"ğŸ“ {self.mode}æ¨¡å¼ä½¿ç”¨ {len(self.files)} ä¸ªæ–‡ä»¶")
    
    def _build_samples(self):
        for file_idx, file_path in enumerate(self.files):
            try:
                with h5py.File(file_path, 'r') as f:
                    n_timesteps = f['data'].shape[0]
                    
                    # å¢åŠ é‡‡æ ·å¯†åº¦
                    step = 1 if self.training else 2
                    for t in range(0, n_timesteps - 1, step):
                        self.samples.append((file_idx, t))
                        
            except Exception as e:
                continue
    
    def _compute_stats(self):
        """è®¡ç®—æ•°æ®ç»Ÿè®¡é‡"""
        print("è®¡ç®—æ•°æ®ç»Ÿè®¡...")
        
        sample_data = []
        for i in range(0, min(200, len(self.samples)), 10):
            try:
                file_idx, timestep = self.samples[i]
                with h5py.File(self.files[file_idx], 'r') as f:
                    data = f['data'][timestep][:22]
                    sample_data.append(data.flatten())
            except:
                continue
        
        if sample_data:
            all_data = np.concatenate(sample_data)
            valid_data = all_data[np.isfinite(all_data)]
            
            if len(valid_data) > 0:
                self.data_mean = float(np.mean(valid_data))
                self.data_std = float(np.std(valid_data))
                print(f"æ•°æ®ç»Ÿè®¡: mean={self.data_mean:.3f}, std={self.data_std:.3f}")
            else:
                self.data_mean = 0.0
                self.data_std = 1.0
        else:
            self.data_mean = 0.0
            self.data_std = 1.0
    
    def __len__(self):
        return len(self.samples)
    
    def __getitem__(self, idx):
        file_idx, timestep = self.samples[idx]
        file_path = self.files[file_idx]
        
        try:
            with h5py.File(file_path, 'r') as f:
                current_data = f['data'][timestep]
                next_data = f['data'][min(timestep + 1, f['data'].shape[0] - 1)]
                
                # è½¬æ¢ä¸ºtensor
                current_tensor = torch.from_numpy(current_data).float()
                next_tensor = torch.from_numpy(next_data).float()
                
                # Resize
                if current_tensor.shape[1:] != self.target_size:
                    current_tensor = F.interpolate(
                        current_tensor.unsqueeze(0), 
                        size=self.target_size, 
                        mode='bilinear', 
                        align_corners=False
                    ).squeeze(0)
                    
                    next_tensor = F.interpolate(
                        next_tensor.unsqueeze(0), 
                        size=self.target_size, 
                        mode='bilinear', 
                        align_corners=False
                    ).squeeze(0)
                
                # åˆ†ç¦»ç‰¹å¾å’Œç›®æ ‡
                env_features = current_tensor[:22]
                initial_fire = current_tensor[22:23]
                target_fire = next_tensor[22:23]
                
                # æ•°æ®æ¸…æ´—
                env_features = self._clean_features(env_features)
                initial_fire = self._clean_fire_state(initial_fire)
                target_fire = self._clean_fire_state(target_fire)
                
                # æ•°æ®å¢å¼º
                if self.training and torch.rand(1) < 0.3:
                    env_features, initial_fire, target_fire = self._augment_data(
                        env_features, initial_fire, target_fire
                    )
                
                return env_features, initial_fire, target_fire
                
        except Exception as e:
            return (torch.zeros(22, *self.target_size),
                   torch.zeros(1, *self.target_size),
                   torch.zeros(1, *self.target_size))
    
    def _clean_features(self, features):
        """æ¸…æ´ç‰¹å¾æ•°æ®"""
        # å¤„ç†NaNå’ŒInf
        features = torch.where(torch.isfinite(features), features, torch.tensor(0.0))
        
        # æ ‡å‡†åŒ–
        if hasattr(self, 'data_mean'):
            features = (features - self.data_mean) / (self.data_std + 1e-8)
        
        # è£å‰ªæå€¼
        features = torch.clamp(features, -5, 5)
        
        return features
    
    def _clean_fire_state(self, fire_state):
        """æ¸…æ´ç«ç¾çŠ¶æ€"""
        fire_state = torch.where(torch.isfinite(fire_state), fire_state, torch.tensor(0.0))
        fire_state = torch.clamp(fire_state, 0, 1)
        return fire_state
    
    def _augment_data(self, env_features, initial_fire, target_fire):
        """æ•°æ®å¢å¼º"""
        # éšæœºæ°´å¹³ç¿»è½¬
        if torch.rand(1) < 0.5:
            env_features = torch.flip(env_features, [2])
            initial_fire = torch.flip(initial_fire, [2])
            target_fire = torch.flip(target_fire, [2])
        
        # éšæœºå‚ç›´ç¿»è½¬
        if torch.rand(1) < 0.5:
            env_features = torch.flip(env_features, [1])
            initial_fire = torch.flip(initial_fire, [1])
            target_fire = torch.flip(target_fire, [1])
        
        # æ·»åŠ è½»å¾®å™ªå£°
        noise_scale = 0.01
        env_features += torch.randn_like(env_features) * noise_scale
        
        return env_features, initial_fire, target_fire

class OptimizedTrainer:
    """ä¼˜åŒ–çš„è®­ç»ƒå™¨"""
    
    def __init__(self, model, train_loader, val_loader, device='cpu'):
        self.model = model.to(device)
        self.train_loader = train_loader
        self.val_loader = val_loader
        self.device = device
        
        # æ”¹è¿›çš„æŸå¤±å‡½æ•°
        self.criterion = FocalLoss(alpha=0.8, gamma=2.0)
        
        # ä¼˜åŒ–å™¨è®¾ç½®
        self.optimizer = torch.optim.AdamW(
            model.parameters(), 
            lr=2e-3,  # ç¨å¤§çš„å­¦ä¹ ç‡
            weight_decay=1e-5  # è¾ƒå°çš„æƒé‡è¡°å‡
        )
        
        # åŠ¨æ€å­¦ä¹ ç‡è°ƒåº¦
        self.scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(
            self.optimizer, T_0=10, T_mult=2, eta_min=1e-6
        )
        
        # è®­ç»ƒå†å²
        self.train_losses = []
        self.val_losses = []
        self.val_auprcs = []
        self.best_val_auprc = 0.0  # æ”¹ä¸ºç›‘æ§AUPRC
        
        print(f"ğŸš€ ä¼˜åŒ–è®­ç»ƒå™¨åˆå§‹åŒ–å®Œæˆ")
        print(f"ğŸ“Š æ¨¡å‹å‚æ•°: {sum(p.numel() for p in model.parameters()):,}")
    
    def train_epoch(self, epoch):
        """è®­ç»ƒä¸€ä¸ªepoch"""
        self.model.train()
        total_loss = 0
        valid_batches = 0
        
        for batch_idx, (env_features, initial_fire, target_fire) in enumerate(self.train_loader):
            env_features = env_features.to(self.device)
            initial_fire = initial_fire.to(self.device)
            target_fire = target_fire.to(self.device)
            
            # è·³è¿‡æ— æ•ˆæ•°æ®
            if (torch.isnan(env_features).any() or torch.isnan(initial_fire).any() or 
                torch.isnan(target_fire).any()):
                continue
            
            self.optimizer.zero_grad()
            
            # å‰å‘ä¼ æ’­
            predicted_fire = self.model(env_features, initial_fire, num_steps=3)
            
            # è®¡ç®—æŸå¤±
            loss = self.criterion(predicted_fire, target_fire)
            
            # æ·»åŠ æ­£åˆ™åŒ–é¡¹
            reg_loss = 0
            for param in self.model.parameters():
                reg_loss += torch.norm(param, 2)
            loss += 1e-6 * reg_loss
            
            if torch.isnan(loss) or torch.isinf(loss):
                continue
            
            # åå‘ä¼ æ’­
            loss.backward()
            torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=0.5)
            self.optimizer.step()
            
            total_loss += loss.item()
            valid_batches += 1
            
            if batch_idx % 50 == 0:
                print(f"  Batch {batch_idx}/{len(self.train_loader)}, Loss: {loss.item():.6f}")
        
        return total_loss / max(valid_batches, 1)
    
    def validate(self):
        """éªŒè¯"""
        self.model.eval()
        total_loss = 0
        all_preds = []
        all_targets = []
        valid_batches = 0
        
        with torch.no_grad():
            for env_features, initial_fire, target_fire in self.val_loader:
                env_features = env_features.to(self.device)
                initial_fire = initial_fire.to(self.device)
                target_fire = target_fire.to(self.device)
                
                if (torch.isnan(env_features).any() or torch.isnan(initial_fire).any() or 
                    torch.isnan(target_fire).any()):
                    continue
                
                predicted_fire = self.model(env_features, initial_fire, num_steps=3)
                loss = self.criterion(predicted_fire, target_fire)
                
                if not (torch.isnan(loss) or torch.isinf(loss)):
                    total_loss += loss.item()
                    valid_batches += 1
                    
                    all_preds.append(predicted_fire.cpu().numpy().flatten())
                    all_targets.append(target_fire.cpu().numpy().flatten())
        
        # è®¡ç®—AUPRC
        if all_preds and all_targets:
            preds = np.concatenate(all_preds)
            targets = np.concatenate(all_targets)
            targets_binary = (targets > 0.5).astype(int)
            
            try:
                auprc = average_precision_score(targets_binary, preds)
            except:
                auprc = 0.0
        else:
            auprc = 0.0
        
        return total_loss / max(valid_batches, 1), auprc
    
    def train(self, num_epochs=30):
        """å®Œæ•´è®­ç»ƒæµç¨‹"""
        print(f"ğŸš€ å¼€å§‹ä¼˜åŒ–CAè®­ç»ƒ {num_epochs} epochs")
        
        save_dir = Path('optimized_ca_outputs')
        save_dir.mkdir(exist_ok=True)
        
        for epoch in range(num_epochs):
            print(f"\nğŸ”¥ Epoch {epoch+1}/{num_epochs}")
            print("-" * 50)
            
            # è®­ç»ƒå’ŒéªŒè¯
            train_loss = self.train_epoch(epoch+1)
            val_loss, val_auprc = self.validate()
            
            # å­¦ä¹ ç‡è°ƒåº¦
            self.scheduler.step()
            current_lr = self.optimizer.param_groups[0]['lr']
            
            # è®°å½•
            self.train_losses.append(train_loss)
            self.val_losses.append(val_loss)
            self.val_auprcs.append(val_auprc)
            
            print(f"ğŸ“Š Results:")
            print(f"  è®­ç»ƒæŸå¤±: {train_loss:.6f}")
            print(f"  éªŒè¯æŸå¤±: {val_loss:.6f}")
            print(f"  éªŒè¯AUPRC: {val_auprc:.4f}")
            print(f"  å­¦ä¹ ç‡: {current_lr:.2e}")
            
            # ä¿å­˜æœ€ä½³æ¨¡å‹ï¼ˆåŸºäºAUPRCï¼‰
            if val_auprc > self.best_val_auprc:
                self.best_val_auprc = val_auprc
                torch.save({
                    'model_state_dict': self.model.state_dict(),
                    'epoch': epoch,
                    'train_loss': train_loss,
                    'val_loss': val_loss,
                    'val_auprc': val_auprc
                }, save_dir / 'best_optimized_ca_model.pth')
                print("ğŸ’¾ ä¿å­˜æœ€ä½³ä¼˜åŒ–CAæ¨¡å‹")
        
        # ç»˜åˆ¶è®­ç»ƒæ›²çº¿
        self.plot_training_curves(save_dir)
        
        print(f"\nâœ… ä¼˜åŒ–CAè®­ç»ƒå®Œæˆ!")
        print(f"ğŸ† æœ€ä½³éªŒè¯AUPRC: {self.best_val_auprc:.4f}")
        
        return self.best_val_auprc
    
    def plot_training_curves(self, save_dir):
        """ç»˜åˆ¶è®­ç»ƒæ›²çº¿"""
        fig, axes = plt.subplots(1, 3, figsize=(15, 5))
        
        epochs = range(1, len(self.train_losses) + 1)
        
        # æŸå¤±æ›²çº¿
        axes[0].plot(epochs, self.train_losses, 'b-', label='è®­ç»ƒæŸå¤±', linewidth=2)
        axes[0].plot(epochs, self.val_losses, 'r-', label='éªŒè¯æŸå¤±', linewidth=2)
        axes[0].set_title('ä¼˜åŒ–CAæŸå¤±æ›²çº¿')
        axes[0].set_xlabel('Epoch')
        axes[0].set_ylabel('Loss')
        axes[0].legend()
        axes[0].grid(True, alpha=0.3)
        
        # AUPRCæ›²çº¿
        axes[1].plot(epochs, self.val_auprcs, 'g-', label='éªŒè¯AUPRC', linewidth=2)
        axes[1].set_title('ä¼˜åŒ–CA AUPRCæ›²çº¿')
        axes[1].set_xlabel('Epoch')
        axes[1].set_ylabel('AUPRC')
        axes[1].legend()
        axes[1].grid(True, alpha=0.3)
        
        # æ”¹è¿›ç»Ÿè®¡
        improvement_text = f"""ä¼˜åŒ–CAæ¨¡å‹æ”¹è¿›:

ğŸ¯ æœ€ä½³AUPRC: {self.best_val_auprc:.4f}
ğŸ“‰ æœ€ä½éªŒè¯æŸå¤±: {min(self.val_losses):.4f}
ğŸ“ˆ AUPRCæå‡: {(max(self.val_auprcs) / (0.05 if max(self.val_auprcs) > 0.05 else 1) - 1) * 100:.1f}%

ä¼˜åŒ–ç­–ç•¥:
âœ… ç®€åŒ–æ¶æ„
âœ… æ”¹è¿›æŸå¤±å‡½æ•°  
âœ… æ•°æ®å¢å¼º
âœ… åŠ¨æ€å­¦ä¹ ç‡
âœ… æ¢¯åº¦è£å‰ª"""
        
        axes[2].text(0.1, 0.5, improvement_text, transform=axes[2].transAxes, 
                    fontsize=10, verticalalignment='center')
        axes[2].set_title('ä¼˜åŒ–æ•ˆæœ')
        axes[2].axis('off')
        
        plt.tight_layout()
        plt.savefig(save_dir / 'optimized_ca_curves.png', dpi=300, bbox_inches='tight')
        plt.show()

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ ä¼˜åŒ–ç‰ˆCAé‡ç«æ¨¡å‹")
    print("=" * 60)
    print("ğŸ¯ é’ˆå¯¹æ€§èƒ½é—®é¢˜çš„ä¼˜åŒ–ç‰ˆæœ¬")
    print("=" * 60)
    
    # ä¼˜åŒ–é…ç½®
    config = {
        'data_dir': 'data/processed',
        'batch_size': 8,  # å¢å¤§batch size
        'num_epochs': 30,
        'max_files': 150,  # å¢åŠ æ•°æ®é‡
        'target_size': (128, 128),
        'device': 'cuda' if torch.cuda.is_available() else 'cpu'
    }
    
    print(f"\nä¼˜åŒ–é…ç½®:")
    for key, value in config.items():
        print(f"  {key}: {value}")
    
    # æ£€æŸ¥æ•°æ®
    data_dir = Path(config['data_dir'])
    if not data_dir.exists():
        print(f"âŒ æ•°æ®ç›®å½•ä¸å­˜åœ¨: {data_dir}")
        return
    
    # åˆ›å»ºå¢å¼ºæ•°æ®é›†
    print(f"\n1. åˆ›å»ºå¢å¼ºæ•°æ®é›†...")
    train_dataset = EnhancedDataset(
        config['data_dir'],
        mode='train',
        max_files=config['max_files'],
        target_size=config['target_size']
    )
    
    val_dataset = EnhancedDataset(
        config['data_dir'],
        mode='val',
        max_files=config['max_files']//4,
        target_size=config['target_size']
    )
    
    # å¤åˆ¶ç»Ÿè®¡é‡
    if hasattr(train_dataset, 'data_mean'):
        val_dataset.data_mean = train_dataset.data_mean
        val_dataset.data_std = train_dataset.data_std
    
    print(f"âœ… è®­ç»ƒé›†: {len(train_dataset)} æ ·æœ¬")
    print(f"âœ… éªŒè¯é›†: {len(val_dataset)} æ ·æœ¬")
    
    if len(train_dataset) == 0:
        print("âŒ è®­ç»ƒé›†ä¸ºç©º")
        return
    
    # åˆ›å»ºæ•°æ®åŠ è½½å™¨
    train_loader = DataLoader(
        train_dataset,
        batch_size=config['batch_size'],
        shuffle=True,
        num_workers=0,
        drop_last=True
    )
    
    val_loader = DataLoader(
        val_dataset,
        batch_size=config['batch_size'],
        shuffle=False,
        num_workers=0
    )
    
    # åˆ›å»ºä¼˜åŒ–æ¨¡å‹
    print(f"\n2. åˆ›å»ºä¼˜åŒ–CAæ¨¡å‹...")
    model = OptimizedCAModel(
        input_channels=22,
        hidden_dim=32
    )
    
    # åˆ›å»ºä¼˜åŒ–è®­ç»ƒå™¨
    print(f"\n3. åˆ›å»ºä¼˜åŒ–è®­ç»ƒå™¨...")
    trainer = OptimizedTrainer(
        model=model,
        train_loader=train_loader,
        val_loader=val_loader,
        device=config['device']
    )
    
    # å¼€å§‹è®­ç»ƒ
    print(f"\n4. å¼€å§‹ä¼˜åŒ–è®­ç»ƒ...")
    best_auprc = trainer.train(num_epochs=config['num_epochs'])
    
    print(f"\nğŸ‰ ä¼˜åŒ–CAè®­ç»ƒå®Œæˆ!")
    print(f"ğŸ† æœ€ä½³AUPRC: {best_auprc:.4f}")
    print(f"ğŸ“ ç»“æœ: optimized_ca_outputs/")

if __name__ == "__main__":
    # è®¾ç½®éšæœºç§å­
    np.random.seed(42)
    torch.manual_seed(42)
    
    try:
        main()
    except Exception as e:
        print(f"è¿è¡Œå‡ºé”™: {e}")
        import traceback
        traceback.print_exc() 