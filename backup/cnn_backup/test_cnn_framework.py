"""
æµ‹è¯•å®Œæ•´çš„é‡ç«CNNå»ºæ¨¡æ¡†æ¶
éªŒè¯æ‰€æœ‰ç»„ä»¶çš„åŠŸèƒ½å’Œé›†æˆ
"""

import sys
import os
sys.path.append('models')

import torch
import torch.nn as nn
import numpy as np
from sklearn.preprocessing import RobustScaler

def test_framework():
    """æµ‹è¯•å®Œæ•´çš„CNNå»ºæ¨¡æ¡†æ¶"""
    print("ğŸ§ª æµ‹è¯•CNNå»ºæ¨¡æ¡†æ¶å®Œæ•´æ€§...")
    
    # 1. æ£€æŸ¥åŸºç¡€ä¾èµ–
    try:
        import torch
        import numpy as np
        from sklearn.preprocessing import RobustScaler
        print("âœ… åŸºç¡€ä¾èµ–æ£€æŸ¥é€šè¿‡")
    except ImportError as e:
        print(f"âŒ åŸºç¡€ä¾èµ–ç¼ºå¤±: {e}")
        return False
    
    # 2. æ£€æŸ¥è‡ªå®šä¹‰æ¨¡å—å¯¼å…¥
    try:
        from wildfire_cnn_model import WildfireCNN, count_parameters
        from wildfire_losses import WildfireLossFactory, FocalLoss
        from wildfire_metrics import WildfireMetrics
        from wildfire_preprocessing import WildfireNormalizer
        print("âœ… è‡ªå®šä¹‰æ¨¡å—å¯¼å…¥æˆåŠŸ")
    except ImportError as e:
        print(f"âŒ è‡ªå®šä¹‰æ¨¡å—å¯¼å…¥å¤±è´¥: {e}")
        return False
    
    # 3. æµ‹è¯•æ¨¡å‹åˆ›å»º
    try:
        model = WildfireCNN(input_channels=23, sequence_length=5)
        param_count = count_parameters(model)
        print(f"âœ… æ¨¡å‹åˆ›å»ºæˆåŠŸï¼Œå‚æ•°æ•°é‡: {param_count:,}")
    except Exception as e:
        print(f"âŒ æ¨¡å‹åˆ›å»ºå¤±è´¥: {e}")
        return False
    
    # 4. æµ‹è¯•æŸå¤±å‡½æ•°
    try:
        loss_fn = WildfireLossFactory.get_recommended_loss(1000.0)
        loss_name = type(loss_fn).__name__
        print(f"âœ… æŸå¤±å‡½æ•°åˆ›å»ºæˆåŠŸ: {loss_name}")
    except Exception as e:
        print(f"âŒ æŸå¤±å‡½æ•°åˆ›å»ºå¤±è´¥: {e}")
        return False
    
    # 5. æµ‹è¯•è¯„ä¼°æŒ‡æ ‡
    try:
        metrics = WildfireMetrics()
        test_pred = torch.rand(2, 1, 64, 64)
        test_target = torch.randint(0, 2, (2, 64, 64)).float()
        result = metrics.compute_metrics(test_pred, test_target)
        auprc_score = result["auprc"]
        print(f"âœ… è¯„ä¼°æŒ‡æ ‡è®¡ç®—æˆåŠŸï¼ŒAUPRC: {auprc_score:.4f}")
    except Exception as e:
        print(f"âŒ è¯„ä¼°æŒ‡æ ‡è®¡ç®—å¤±è´¥: {e}")
        return False
    
    # 6. æµ‹è¯•é¢„å¤„ç†
    try:
        normalizer = WildfireNormalizer(method='robust')
        test_data = np.random.randn(10, 23)
        normalized = normalizer.fit_transform(test_data)
        print(f"âœ… æ•°æ®é¢„å¤„ç†æˆåŠŸï¼Œå½¢çŠ¶: {normalized.shape}")
    except Exception as e:
        print(f"âŒ æ•°æ®é¢„å¤„ç†å¤±è´¥: {e}")
        return False
    
    # 7. æµ‹è¯•å®Œæ•´å‰å‘ä¼ æ’­
    try:
        model.eval()
        batch_size, seq_len, channels, height, width = 2, 5, 23, 64, 64
        test_input = torch.randn(batch_size, seq_len, channels, height, width)
        
        # è®¾ç½®åœŸåœ°è¦†ç›–é€šé“(16)ä¸ºåˆç†çš„ç±»åˆ«å€¼(1-16)
        test_input[:, :, 16, :, :] = torch.randint(1, 17, (batch_size, seq_len, height, width)).float()
        
        # å‰å‘ä¼ æ’­
        with torch.no_grad():
            output = model(test_input)
        
        expected_shape = (batch_size, 1, height, width)
        if output.shape == expected_shape:
            print(f"âœ… å‰å‘ä¼ æ’­æˆåŠŸï¼Œè¾“å‡ºå½¢çŠ¶: {output.shape}")
        else:
            print(f"âŒ è¾“å‡ºå½¢çŠ¶ä¸æ­£ç¡®: æœŸæœ› {expected_shape}, å¾—åˆ° {output.shape}")
            return False
            
    except Exception as e:
        print(f"âŒ å‰å‘ä¼ æ’­å¤±è´¥: {e}")
        return False
    
    # 8. æµ‹è¯•æŸå¤±è®¡ç®—
    try:
        target = torch.randint(0, 2, (batch_size, height, width)).float()
        loss = loss_fn(output, target)
        print(f"âœ… æŸå¤±è®¡ç®—æˆåŠŸï¼ŒæŸå¤±å€¼: {loss.item():.6f}")
    except Exception as e:
        print(f"âŒ æŸå¤±è®¡ç®—å¤±è´¥: {e}")
        return False
    
    print("ğŸ‰ CNNå»ºæ¨¡æ¡†æ¶å®Œæ•´æ€§æµ‹è¯•å®Œæˆï¼æ‰€æœ‰ç»„ä»¶æ­£å¸¸å·¥ä½œ")
    return True

def test_mini_training():
    """æµ‹è¯•è¿·ä½ è®­ç»ƒæµç¨‹"""
    print("\nğŸš€ æµ‹è¯•è¿·ä½ è®­ç»ƒæµç¨‹...")
    
    try:
        from wildfire_cnn_model import WildfireCNN
        from wildfire_losses import FocalLoss
        from wildfire_metrics import WildfireMetrics
        
        # åˆ›å»ºæ¨¡å‹å’Œç»„ä»¶
        device = torch.device('cpu')  # ä½¿ç”¨CPUé¿å…GPUä¾èµ–
        model = WildfireCNN(input_channels=23, sequence_length=3, 
                           unet_features=[32, 64], lstm_hidden_dims=[64])
        model = model.to(device)
        
        criterion = FocalLoss(alpha=0.25, gamma=2.0)
        optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)
        metrics_calc = WildfireMetrics(device=device)
        
        # åˆ›å»ºæ¨¡æ‹Ÿæ•°æ®
        batch_size, seq_len, channels = 2, 3, 23
        height, width = 32, 32  # å°å°ºå¯¸å¿«é€Ÿæµ‹è¯•
        
        train_data = torch.randn(batch_size, seq_len, channels, height, width).to(device)
        # è®¾ç½®åœŸåœ°è¦†ç›–é€šé“ä¸ºåˆç†å€¼
        train_data[:, :, 16, :, :] = torch.randint(1, 17, (batch_size, seq_len, height, width)).float().to(device)
        train_targets = torch.randint(0, 2, (batch_size, height, width)).float().to(device)
        
        # æ¨¡æ‹Ÿå‡ æ­¥è®­ç»ƒ
        model.train()
        train_losses = []
        
        for step in range(3):
            optimizer.zero_grad()
            
            # å‰å‘ä¼ æ’­
            outputs = model(train_data)
            loss = criterion(outputs, train_targets)
            
            # åå‘ä¼ æ’­
            loss.backward()
            optimizer.step()
            
            train_losses.append(loss.item())
            print(f"  Step {step+1}: Loss = {loss.item():.6f}")
        
        # æµ‹è¯•è¯„ä¼°
        model.eval()
        with torch.no_grad():
            val_outputs = model(train_data)
            val_metrics = metrics_calc.compute_metrics(val_outputs, train_targets)
        
        print(f"âœ… è¿·ä½ è®­ç»ƒå®Œæˆ")
        print(f"   æœ€ç»ˆæŸå¤±: {train_losses[-1]:.6f}")
        print(f"   éªŒè¯AUPRC: {val_metrics['auprc']:.4f}")
        print(f"   éªŒè¯IoU: {val_metrics['iou']:.4f}")
        
        return True
        
    except Exception as e:
        print(f"âŒ è¿·ä½ è®­ç»ƒå¤±è´¥: {e}")
        return False

if __name__ == "__main__":
    # æµ‹è¯•æ¡†æ¶
    framework_ok = test_framework()
    
    if framework_ok:
        # æµ‹è¯•è®­ç»ƒæµç¨‹
        training_ok = test_mini_training()
        
        if training_ok:
            print("\nğŸ‰ å®Œæ•´çš„CNNå»ºæ¨¡æ¡†æ¶æµ‹è¯•é€šè¿‡ï¼")
            print("ğŸ“‹ æ¡†æ¶åŒ…å«ä»¥ä¸‹ç»„ä»¶:")
            print("   â€¢ 23é€šé“å¤šæ¨¡æ€æ•°æ®åŠ è½½å™¨")
            print("   â€¢ U-Net + ConvLSTMæ—¶ç©ºCNNæ¨¡å‹")
            print("   â€¢ Focal Losså¤„ç†ç±»åˆ«ä¸å¹³è¡¡")
            print("   â€¢ åˆ†ç±»åˆ«ç‰¹å¾æ ‡å‡†åŒ–")
            print("   â€¢ ç‰©ç†ä¸€è‡´æ€§æ•°æ®å¢å¼º")
            print("   â€¢ ä¸“ä¸šé‡ç«è¯„ä¼°æŒ‡æ ‡(AUPRC, IoUç­‰)")
            print("   â€¢ å®Œæ•´è®­ç»ƒå’ŒéªŒè¯æµç¨‹")
            print("\nğŸš€ å‡†å¤‡å¥½å¼€å§‹æ­£å¼è®­ç»ƒäº†ï¼")
        else:
            print("\nâŒ è®­ç»ƒæµç¨‹æµ‹è¯•å¤±è´¥")
    else:
        print("\nâŒ æ¡†æ¶ç»„ä»¶æµ‹è¯•å¤±è´¥") 