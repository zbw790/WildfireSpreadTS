"""
WildFire Data Preprocessing
ä¸“ç”¨äºé‡ç«ä¼ æ’­é¢„æµ‹çš„æ•°æ®é¢„å¤„ç†æ¨¡å—ï¼ŒåŒ…å«ç‰¹å¾å·¥ç¨‹ã€æ ‡å‡†åŒ–å’Œæ•°æ®å¢å¼º
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
import numpy as np
from typing import Dict, List, Tuple, Optional, Any
from sklearn.preprocessing import StandardScaler, RobustScaler, MinMaxScaler
import warnings

class WildfireFeatureProcessor:
    """
    é‡ç«ç‰¹å¾å¤„ç†å™¨
    """
    
    def __init__(self):
        # 23é€šé“ç‰¹å¾å®šä¹‰
        self.feature_names = [
            'VIIRS_M11', 'VIIRS_I2', 'VIIRS_I1', 'NDVI', 'EVI2',  # 0-4: é¥æ„Ÿ
            'Precipitation_Total', 'Wind_Speed', 'Wind_Direction',  # 5-7: æ°”è±¡å†å²
            'Temperature_Min', 'Temperature_Max', 'ERC', 'Specific_Humidity',  # 8-11: æ°”è±¡å†å²
            'Slope', 'Aspect', 'Elevation', 'PDSI',  # 12-15: åœ°å½¢+å¹²æ—±
            'Land_Cover_Class',  # 16: åœŸåœ°è¦†ç›–
            'Forecast_Precipitation', 'Forecast_Wind_Speed',  # 17-18: é¢„æµ‹æ°”è±¡
            'Forecast_Wind_Direction', 'Forecast_Temperature',  # 19-20: é¢„æµ‹æ°”è±¡
            'Forecast_Specific_Humidity',  # 21: é¢„æµ‹æ°”è±¡
            'Active_Fire_Confidence'  # 22: ç«ç‚¹ç½®ä¿¡åº¦
        ]
        
        # ç‰¹å¾åˆ†ç»„
        self.feature_groups = {
            'remote_sensing': [0, 1, 2],  # VIIRS
            'vegetation': [3, 4],  # NDVI, EVI2
            'weather_hist': [5, 6, 7, 8, 9, 10, 11],  # å†å²æ°”è±¡
            'topography': [12, 13, 14],  # åœ°å½¢
            'drought': [15],  # å¹²æ—±æŒ‡æ•°
            'landcover': [16],  # åœŸåœ°è¦†ç›–
            'weather_forecast': [17, 18, 19, 20, 21],  # é¢„æµ‹æ°”è±¡
            'fire': [22]  # ç«ç‚¹
        }
        
        # ç‰¹å¾ç‰©ç†çº¦æŸ
        self.feature_constraints = {
            'VIIRS_M11': {'min': 38, 'max': 11886, 'cyclic': False},
            'VIIRS_I2': {'min': -100, 'max': 15893, 'cyclic': False},
            'VIIRS_I1': {'min': -100, 'max': 15666, 'cyclic': False},
            'NDVI': {'min': -1405, 'max': 9736, 'cyclic': False},
            'EVI2': {'min': -843, 'max': 6075, 'cyclic': False},
            'Precipitation_Total': {'min': 0, 'max': 100, 'cyclic': False},
            'Wind_Speed': {'min': 0, 'max': 50, 'cyclic': False},
            'Wind_Direction': {'min': 0, 'max': 360, 'cyclic': True},
            'Temperature_Min': {'min': 200, 'max': 350, 'cyclic': False},
            'Temperature_Max': {'min': 200, 'max': 350, 'cyclic': False},
            'ERC': {'min': 0, 'max': 200, 'cyclic': False},
            'Specific_Humidity': {'min': 0, 'max': 0.05, 'cyclic': False},
            'Slope': {'min': 0, 'max': 90, 'cyclic': False},
            'Aspect': {'min': 0, 'max': 360, 'cyclic': True},
            'Elevation': {'min': 0, 'max': 5000, 'cyclic': False},
            'PDSI': {'min': -10, 'max': 10, 'cyclic': False},
            'Land_Cover_Class': {'min': 1, 'max': 16, 'cyclic': False},
            'Active_Fire_Confidence': {'min': 0, 'max': 100, 'cyclic': False}
        }
    
    def apply_feature_constraints(self, data: np.ndarray, feature_idx: int) -> np.ndarray:
        """åº”ç”¨ç‰¹å¾ç‰©ç†çº¦æŸ"""
        feature_name = self.feature_names[feature_idx]
        constraints = self.feature_constraints.get(feature_name, {})
        
        if 'min' in constraints and 'max' in constraints:
            data = np.clip(data, constraints['min'], constraints['max'])
        
        return data
    
    def compute_derived_features(self, data: np.ndarray) -> Dict[str, np.ndarray]:
        """è®¡ç®—è¡ç”Ÿç‰¹å¾"""
        derived = {}
        
        # æ¸©åº¦ç›¸å…³
        if len(data) > 9:  # ç¡®ä¿æœ‰æ¸©åº¦æ•°æ®
            temp_min = data[8]  # Temperature_Min
            temp_max = data[9]  # Temperature_Max
            derived['temperature_range'] = temp_max - temp_min
            derived['temperature_mean'] = (temp_max + temp_min) / 2
        
        # é£ç›¸å…³
        if len(data) > 7:
            wind_speed = data[6]  # Wind_Speed
            wind_dir = data[7]    # Wind_Direction (degrees)
            
            # é£çŸ¢é‡åˆ†è§£
            wind_dir_rad = np.deg2rad(wind_dir)
            derived['wind_u'] = wind_speed * np.cos(wind_dir_rad)  # ä¸œè¥¿åˆ†é‡
            derived['wind_v'] = wind_speed * np.sin(wind_dir_rad)  # å—åŒ—åˆ†é‡
        
        # æ¹¿åº¦ç›¸å…³
        if len(data) > 11 and len(data) > 5:
            humidity = data[11]  # Specific_Humidity
            precipitation = data[5]  # Precipitation_Total
            derived['moisture_index'] = humidity + 0.1 * precipitation
        
        # ç«é™©ç­‰çº§
        if len(data) > 10 and len(data) > 6:
            erc = data[10]  # ERC
            wind_speed = data[6]  # Wind_Speed
            derived['fire_danger_index'] = erc * (1 + 0.1 * wind_speed)
        
        # åœ°å½¢æ•ˆåº”
        if len(data) > 14:
            slope = data[12]    # Slope
            aspect = data[13]   # Aspect
            elevation = data[14]  # Elevation
            
            # å¡å‘æ•ˆåº”ï¼ˆå—å¡æ›´å¹²ç‡¥ï¼‰
            aspect_rad = np.deg2rad(aspect)
            derived['south_facing_effect'] = np.cos(aspect_rad)  # 1=æ­£å—ï¼Œ-1=æ­£åŒ—
            
            # åœ°å½¢å¤æ‚åº¦
            derived['terrain_complexity'] = slope * (elevation / 1000)
        
        return derived

class WildfireNormalizer:
    """
    é‡ç«æ•°æ®æ ‡å‡†åŒ–å™¨
    """
    
    def __init__(self, method: str = 'robust'):
        """
        Args:
            method: æ ‡å‡†åŒ–æ–¹æ³• ('standard', 'robust', 'minmax')
        """
        self.method = method
        self.scalers = {}
        self.fitted = False
        
        # ç‰¹å¾åˆ†ç»„
        self.feature_groups = {
            'remote_sensing': [0, 1, 2],
            'vegetation': [3, 4], 
            'weather': [5, 6, 8, 9, 10, 11, 17, 18, 20, 21],  # éæ–¹å‘æ€§æ°”è±¡
            'wind_direction': [7, 19],  # é£å‘ï¼ˆéœ€è¦ç‰¹æ®Šå¤„ç†ï¼‰
            'topography': [12, 14],  # å¡åº¦å’Œæµ·æ‹”
            'aspect': [13],  # å¡å‘ï¼ˆå¾ªç¯ç‰¹å¾ï¼‰
            'drought': [15],
            'landcover': [16],
            'fire': [22]
        }
    
    def _create_scaler(self) -> Any:
        """åˆ›å»ºæ ‡å‡†åŒ–å™¨"""
        if self.method == 'standard':
            return StandardScaler()
        elif self.method == 'robust':
            return RobustScaler()
        elif self.method == 'minmax':
            return MinMaxScaler()
        else:
            raise ValueError(f"Unknown normalization method: {self.method}")
    
    def _normalize_circular_features(self, data: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:
        """
        å¤„ç†å¾ªç¯ç‰¹å¾ï¼ˆå¦‚é£å‘ã€å¡å‘ï¼‰
        è½¬æ¢ä¸ºsin/cosåˆ†é‡
        """
        # è½¬æ¢ä¸ºå¼§åº¦
        data_rad = np.deg2rad(data)
        
        # è½¬æ¢ä¸ºsin/cosåˆ†é‡
        sin_component = np.sin(data_rad)
        cos_component = np.cos(data_rad)
        
        return sin_component, cos_component
    
    def fit(self, data: np.ndarray):
        """
        æ‹Ÿåˆæ ‡å‡†åŒ–å™¨
        
        Args:
            data: (N, C) æˆ– (N, T, C) æˆ– (N, T, C, H, W) æ•°æ®
        """
        # é‡å¡‘æ•°æ®ä¸º (samples, features)
        original_shape = data.shape
        if len(original_shape) == 5:  # (N, T, C, H, W)
            data = data.reshape(-1, original_shape[2])
        elif len(original_shape) == 3:  # (N, T, C)
            data = data.reshape(-1, original_shape[2])
        elif len(original_shape) == 2:  # (N, C)
            pass
        else:
            raise ValueError(f"Unsupported data shape: {original_shape}")
        
        # è¿‡æ»¤æœ‰æ•ˆå€¼
        valid_mask = np.isfinite(data).all(axis=1)
        data = data[valid_mask]
        
        if len(data) == 0:
            warnings.warn("No valid data for fitting normalizer")
            return
        
        # ä¸ºæ¯ä¸ªç‰¹å¾ç»„åˆ›å»ºæ ‡å‡†åŒ–å™¨
        for group_name, indices in self.feature_groups.items():
            if group_name in ['wind_direction', 'aspect']:
                # å¾ªç¯ç‰¹å¾ä¸éœ€è¦æ ‡å‡†åŒ–
                continue
            
            if all(idx < data.shape[1] for idx in indices):
                group_data = data[:, indices]
                scaler = self._create_scaler()
                scaler.fit(group_data)
                self.scalers[group_name] = scaler
        
        self.fitted = True
        print(f"æ ‡å‡†åŒ–å™¨æ‹Ÿåˆå®Œæˆï¼Œä½¿ç”¨æ–¹æ³•: {self.method}")
    
    def transform(self, data: np.ndarray) -> np.ndarray:
        """
        åº”ç”¨æ ‡å‡†åŒ–
        
        Args:
            data: è¾“å…¥æ•°æ®
            
        Returns:
            normalized_data: æ ‡å‡†åŒ–åçš„æ•°æ®
        """
        if not self.fitted:
            raise ValueError("Normalizer not fitted. Call fit() first.")
        
        original_shape = data.shape
        
        # é‡å¡‘æ•°æ®
        if len(original_shape) == 5:  # (N, T, C, H, W)
            data = data.reshape(-1, original_shape[2])
            spatial_dims = original_shape[3:]
        elif len(original_shape) == 3:  # (N, T, C)
            data = data.reshape(-1, original_shape[2])
            spatial_dims = None
        elif len(original_shape) == 2:  # (N, C)
            spatial_dims = None
        else:
            raise ValueError(f"Unsupported data shape: {original_shape}")
        
        normalized_data = data.copy()
        
        # åº”ç”¨å„ç»„æ ‡å‡†åŒ–
        for group_name, indices in self.feature_groups.items():
            if group_name in ['wind_direction', 'aspect']:
                # å¤„ç†å¾ªç¯ç‰¹å¾
                for idx in indices:
                    if idx < data.shape[1]:
                        circular_data = data[:, idx]
                        sin_comp, cos_comp = self._normalize_circular_features(circular_data)
                        
                        # æ›¿æ¢åŸå§‹æ•°æ®ä¸ºsinåˆ†é‡ï¼Œcosåˆ†é‡éœ€è¦é¢å¤–å¤„ç†
                        normalized_data[:, idx] = sin_comp
                        # æ³¨æ„ï¼šè¿™é‡Œæˆ‘ä»¬åªä¿ç•™sinåˆ†é‡ï¼Œå®é™…ä½¿ç”¨ä¸­å¯èƒ½éœ€è¦æ‰©å±•ç»´åº¦
                continue
            
            if group_name in self.scalers and all(idx < data.shape[1] for idx in indices):
                scaler = self.scalers[group_name]
                group_data = data[:, indices]
                normalized_group = scaler.transform(group_data)
                normalized_data[:, indices] = normalized_group
        
        # æ¢å¤åŸå§‹å½¢çŠ¶
        if len(original_shape) == 5:
            normalized_data = normalized_data.reshape(original_shape)
        elif len(original_shape) == 3:
            normalized_data = normalized_data.reshape(original_shape)
        
        return normalized_data
    
    def fit_transform(self, data: np.ndarray) -> np.ndarray:
        """æ‹Ÿåˆå¹¶åº”ç”¨æ ‡å‡†åŒ–"""
        self.fit(data)
        return self.transform(data)

class WildfireAugmenter:
    """
    é‡ç«æ•°æ®å¢å¼ºå™¨
    ä¿æŒç‰©ç†ä¸€è‡´æ€§çš„æ•°æ®å¢å¼º
    """
    
    def __init__(
        self,
        flip_prob: float = 0.5,
        rotate_prob: float = 0.3,
        noise_prob: float = 0.2,
        weather_perturb_prob: float = 0.3,
        noise_std: float = 0.01
    ):
        self.flip_prob = flip_prob
        self.rotate_prob = rotate_prob
        self.noise_prob = noise_prob
        self.weather_perturb_prob = weather_perturb_prob
        self.noise_std = noise_std
        
        # å¯ä»¥æ·»åŠ å™ªå£°çš„ç‰¹å¾ï¼ˆæ°”è±¡æ•°æ®ï¼‰
        self.noise_channels = [5, 6, 8, 9, 10, 11, 17, 18, 20, 21]  # æ°”è±¡ç‰¹å¾
        
        # é£å‘é€šé“ï¼ˆéœ€è¦ç‰¹æ®Šå¤„ç†ï¼‰
        self.wind_direction_channels = [7, 19]  # å†å²é£å‘ï¼Œé¢„æµ‹é£å‘
    
    def _flip_horizontal(self, data: np.ndarray, target: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:
        """æ°´å¹³ç¿»è½¬ï¼ˆä¿æŒé£å‘ä¸€è‡´æ€§ï¼‰"""
        # ç¿»è½¬æ•°æ®
        data_flipped = np.flip(data, axis=-1)
        target_flipped = np.flip(target, axis=-1)
        
        # è°ƒæ•´é£å‘ï¼ˆæ°´å¹³ç¿»è½¬åé£å‘éœ€è¦é•œåƒï¼‰
        for ch in self.wind_direction_channels:
            if ch < data.shape[-3]:  # ç¡®ä¿é€šé“å­˜åœ¨
                wind_dir = data_flipped[..., ch, :, :]
                # æ°´å¹³ç¿»è½¬: E-Wåå‘ï¼ŒN-Sä¿æŒ
                # æ–°é£å‘ = 360 - åŸé£å‘ï¼ˆå¯¹äº0-360åº¦ï¼‰
                wind_dir_new = 360 - wind_dir
                wind_dir_new = wind_dir_new % 360
                data_flipped[..., ch, :, :] = wind_dir_new
        
        return data_flipped, target_flipped
    
    def _flip_vertical(self, data: np.ndarray, target: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:
        """å‚ç›´ç¿»è½¬ï¼ˆä¿æŒé£å‘ä¸€è‡´æ€§ï¼‰"""
        # ç¿»è½¬æ•°æ®
        data_flipped = np.flip(data, axis=-2)
        target_flipped = np.flip(target, axis=-2)
        
        # è°ƒæ•´é£å‘ï¼ˆå‚ç›´ç¿»è½¬åé£å‘éœ€è¦è°ƒæ•´ï¼‰
        for ch in self.wind_direction_channels:
            if ch < data.shape[-3]:
                wind_dir = data_flipped[..., ch, :, :]
                # å‚ç›´ç¿»è½¬: N-Såå‘ï¼ŒE-Wä¿æŒ
                # æ–°é£å‘ = 180 - åŸé£å‘
                wind_dir_new = 180 - wind_dir
                wind_dir_new = wind_dir_new % 360
                data_flipped[..., ch, :, :] = wind_dir_new
        
        return data_flipped, target_flipped
    
    def _rotate_90(self, data: np.ndarray, target: np.ndarray, k: int) -> Tuple[np.ndarray, np.ndarray]:
        """90åº¦å€æ•°æ—‹è½¬ï¼ˆä¿æŒé£å‘ä¸€è‡´æ€§ï¼‰"""
        # æ—‹è½¬æ•°æ®
        data_rotated = np.rot90(data, k, axes=(-2, -1))
        target_rotated = np.rot90(target, k, axes=(-2, -1))
        
        # è°ƒæ•´é£å‘
        angle_adjustment = k * 90  # æ—‹è½¬è§’åº¦
        for ch in self.wind_direction_channels:
            if ch < data.shape[-3]:
                wind_dir = data_rotated[..., ch, :, :]
                wind_dir_new = (wind_dir + angle_adjustment) % 360
                data_rotated[..., ch, :, :] = wind_dir_new
        
        return data_rotated, target_rotated
    
    def _add_weather_noise(self, data: np.ndarray) -> np.ndarray:
        """æ·»åŠ æ°”è±¡å™ªå£°ï¼ˆæ¨¡æ‹Ÿæµ‹é‡ä¸ç¡®å®šæ€§ï¼‰"""
        data_noisy = data.copy()
        
        for ch in self.noise_channels:
            if ch < data.shape[-3]:
                noise = np.random.normal(0, self.noise_std, data[..., ch, :, :].shape)
                data_noisy[..., ch, :, :] += noise
        
        return data_noisy
    
    def _perturb_weather(self, data: np.ndarray) -> np.ndarray:
        """æ‰°åŠ¨æ°”è±¡æ¡ä»¶ï¼ˆæ¨¡æ‹Ÿå¤©æ°”å˜åŒ–ï¼‰"""
        data_perturbed = data.copy()
        
        # æ¸©åº¦æ‰°åŠ¨ (Â±2K)
        for temp_ch in [8, 9, 20]:  # Temperature_Min, Temperature_Max, Forecast_Temperature
            if temp_ch < data.shape[-3]:
                temp_delta = np.random.uniform(-2, 2, data[..., temp_ch, :, :].shape)
                data_perturbed[..., temp_ch, :, :] += temp_delta
        
        # é£é€Ÿæ‰°åŠ¨ (Â±10%)
        for wind_ch in [6, 18]:  # Wind_Speed, Forecast_Wind_Speed
            if wind_ch < data.shape[-3]:
                wind_factor = np.random.uniform(0.9, 1.1, data[..., wind_ch, :, :].shape)
                data_perturbed[..., wind_ch, :, :] *= wind_factor
        
        # æ¹¿åº¦æ‰°åŠ¨ (Â±10%)
        for humid_ch in [11, 21]:  # Specific_Humidity, Forecast_Specific_Humidity
            if humid_ch < data.shape[-3]:
                humid_factor = np.random.uniform(0.9, 1.1, data[..., humid_ch, :, :].shape)
                data_perturbed[..., humid_ch, :, :] *= humid_factor
        
        return data_perturbed
    
    def augment(self, data: np.ndarray, target: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:
        """
        åº”ç”¨æ•°æ®å¢å¼º
        
        Args:
            data: (T, C, H, W) è¾“å…¥ç‰¹å¾
            target: (H, W) ç›®æ ‡æ ‡ç­¾
            
        Returns:
            augmented_data, augmented_target
        """
        augmented_data = data.copy()
        augmented_target = target.copy()
        
        # æ°´å¹³ç¿»è½¬
        if np.random.random() < self.flip_prob:
            augmented_data, augmented_target = self._flip_horizontal(augmented_data, augmented_target)
        
        # å‚ç›´ç¿»è½¬
        if np.random.random() < self.flip_prob:
            augmented_data, augmented_target = self._flip_vertical(augmented_data, augmented_target)
        
        # æ—‹è½¬
        if np.random.random() < self.rotate_prob:
            k = np.random.randint(1, 4)  # 90, 180, 270åº¦
            augmented_data, augmented_target = self._rotate_90(augmented_data, augmented_target, k)
        
        # æ·»åŠ å™ªå£°
        if np.random.random() < self.noise_prob:
            augmented_data = self._add_weather_noise(augmented_data)
        
        # æ‰°åŠ¨æ°”è±¡æ¡ä»¶
        if np.random.random() < self.weather_perturb_prob:
            augmented_data = self._perturb_weather(augmented_data)
        
        return augmented_data, augmented_target

def test_preprocessing():
    """æµ‹è¯•é¢„å¤„ç†åŠŸèƒ½"""
    print("ğŸ§ª æµ‹è¯•é‡ç«æ•°æ®é¢„å¤„ç†...")
    
    # åˆ›å»ºæµ‹è¯•æ•°æ®
    batch_size, seq_len, channels, height, width = 4, 5, 23, 64, 64
    
    # æ¨¡æ‹ŸçœŸå®æ•°æ®èŒƒå›´
    data = np.random.randn(batch_size, seq_len, channels, height, width)
    
    # è®¾ç½®çœŸå®çš„æ•°æ®èŒƒå›´
    data[:, :, 0, :, :] = np.random.uniform(38, 11886, (batch_size, seq_len, height, width))  # VIIRS_M11
    data[:, :, 6, :, :] = np.random.uniform(0, 10, (batch_size, seq_len, height, width))      # Wind_Speed
    data[:, :, 7, :, :] = np.random.uniform(0, 360, (batch_size, seq_len, height, width))    # Wind_Direction
    
    target = np.random.choice([0, 1], size=(batch_size, height, width), p=[0.95, 0.05])
    
    print(f"åŸå§‹æ•°æ®å½¢çŠ¶: {data.shape}")
    print(f"ç›®æ ‡å½¢çŠ¶: {target.shape}")
    
    # æµ‹è¯•ç‰¹å¾å¤„ç†å™¨
    print("\nğŸ“Š æµ‹è¯•ç‰¹å¾å¤„ç†å™¨...")
    processor = WildfireFeatureProcessor()
    
    # è®¡ç®—è¡ç”Ÿç‰¹å¾
    sample_data = data[0, 0, :, 32, 32]  # å–ä¸€ä¸ªåƒç´ çš„æ•°æ®
    derived_features = processor.compute_derived_features(sample_data)
    print(f"è¡ç”Ÿç‰¹å¾æ•°é‡: {len(derived_features)}")
    
    # æµ‹è¯•æ ‡å‡†åŒ–å™¨
    print("\nğŸ”§ æµ‹è¯•æ ‡å‡†åŒ–å™¨...")
    normalizer = WildfireNormalizer(method='robust')
    
    # æ‹Ÿåˆå¹¶å˜æ¢
    normalized_data = normalizer.fit_transform(data)
    print(f"æ ‡å‡†åŒ–å‰èŒƒå›´: [{data.min():.2f}, {data.max():.2f}]")
    print(f"æ ‡å‡†åŒ–åèŒƒå›´: [{normalized_data.min():.2f}, {normalized_data.max():.2f}]")
    
    # æµ‹è¯•æ•°æ®å¢å¼ºå™¨
    print("\nğŸ² æµ‹è¯•æ•°æ®å¢å¼ºå™¨...")
    augmenter = WildfireAugmenter()
    
    sample_sequence = data[0]  # (T, C, H, W)
    sample_target = target[0]  # (H, W)
    
    aug_data, aug_target = augmenter.augment(sample_sequence, sample_target)
    print(f"å¢å¼ºå‰æ•°æ®å½¢çŠ¶: {sample_sequence.shape}")
    print(f"å¢å¼ºåæ•°æ®å½¢çŠ¶: {aug_data.shape}")
    print(f"é£å‘å˜åŒ–: {sample_sequence[0, 7, 32, 32]:.1f}Â° -> {aug_data[0, 7, 32, 32]:.1f}Â°")
    
    print("âœ… é¢„å¤„ç†æµ‹è¯•å®Œæˆï¼")

if __name__ == "__main__":
    test_preprocessing() 